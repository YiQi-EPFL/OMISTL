{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "test_shortestpath.ipynb",
   "provenance": [],
   "authorship_tag": "ABX9TyOtRSeDtZbei9JgzmnCBc02"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# import os\n",
    "# os.chdir('/content/drive/MyDrive/project/OMISTL/MPC')\n",
    "# os.chdir('/content/drive/MyDrive/Colab Notebooks/OMISTL/MPC')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# !pip3 install graycode\n",
    "# !pip3 install treelib\n",
    "# !pip3 install cvxpy==1.1.20\n",
    "# !pip3 install mosek==9.3.20"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from solvers.OMISTL import OMISTL\n",
    "import cvxpy as cp\n",
    "from utils import *\n",
    "import pickle, os\n",
    "from MPC_prob import MPC\n",
    "\n",
    "from tqdm import tqdm\n",
    "from para import paraset\n",
    "from test_results import test_strategy\n",
    "from test_results import load_result\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'#不设这个解不出#"
   ],
   "metadata": {
    "id": "73M8ow_96uHi",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1658326900014,
     "user_tz": -120,
     "elapsed": 3774,
     "user": {
      "displayName": "Qi Yi",
      "userId": "03240543293609466208"
     }
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msi\\anaconda3\\envs\\coco\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\msi\\anaconda3\\envs\\coco\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\msi\\anaconda3\\envs\\coco\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "N= 12\n",
    "n_obs = 6\n",
    "paraset(N=N, n_obs=n_obs,Qs=1,Rs=0,num_probs=20000,obs_default=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only - expires 2022-12-22\n",
      "Using license file C:\\Users\\msi\\gurobi.lic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/20000 [00:04<1:39:14,  3.36it/s]C:\\Users\\msi\\anaconda3\\envs\\coco\\lib\\site-packages\\cvxpy\\problems\\problem.py:1306: UserWarning: \n",
      "    The problem is either infeasible or unbounded, but the solver\n",
      "    cannot tell which. Disable any solver-specific presolve methods\n",
      "    and re-solve to determine the precise problem status.\n",
      "\n",
      "    For GUROBI and CPLEX you can automatically perform this re-solve\n",
      "    with the keyword argument prob.solve(reoptimize=True, ...).\n",
      "    \n",
      "  warnings.warn(INF_OR_UNB_MESSAGE)\n",
      "100%|██████████| 20000/20000 [1:31:46<00:00,  3.63it/s]  \n"
     ]
    }
   ],
   "source": [
    "#pass the value from config to dict and para\n",
    "relative_path = os.getcwd()\n",
    "dataset_name = 'MPC_horizon_{}_obs_{}'.format(N,n_obs)\n",
    "# dataset_name = 'NSTL_{}_horizon_{}'.format(Qs, N)\n",
    "config_fn = os.path.join(relative_path, 'config', dataset_name+'.p')\n",
    "\n",
    "# config = [dataset_name, [prob_params] ,sampled_params]\n",
    "outfile = open(config_fn,\"rb\")\n",
    "config=pickle.load(outfile)\n",
    "outfile.close()\n",
    "\n",
    "train_fn = 'train_horizon_{}.p'.format(N)\n",
    "train_fn = os.path.join(relative_path, 'data', dataset_name, train_fn)\n",
    "test_fn = 'test_horizon_{}.p'.format(N)\n",
    "test_fn = os.path.join(relative_path, 'data', dataset_name, test_fn)\n",
    "\n",
    "all_params = ['N', 'Ak', 'Bk', 'Q', 'R', 'n_obs', \\\n",
    "            'posmin', 'posmax', 'velmin', 'velmax', \\\n",
    "            'umin', 'umax']\n",
    "\n",
    "param_dict={}\n",
    "i=0\n",
    "len_para = len(all_params)\n",
    "for param in all_params:\n",
    "    param_dict[param]= config[1][i]\n",
    "    i+=1\n",
    "    if i == len_para:\n",
    "        break\n",
    "\n",
    "N = param_dict['N']\n",
    "Ak = param_dict['Ak']\n",
    "Bk = param_dict['Bk']\n",
    "Q = param_dict['Q']\n",
    "R = param_dict['R']\n",
    "n_obs = param_dict['n_obs']\n",
    "umin = param_dict['umin']\n",
    "umax = param_dict['umax']\n",
    "sampled_params = config[2]\n",
    "n_obs = config[3]\n",
    "num_probs = config[4]\n",
    "border_size = config[5]\n",
    "box_buffer = config[6]\n",
    "min_box_size = config[7]\n",
    "max_box_size = config[8]\n",
    "posmin = config[9]\n",
    "posmax = config[10]\n",
    "velmin = config[11]\n",
    "velmax = config[12]\n",
    "n = config[13]\n",
    "m= config[14]\n",
    "\n",
    "obs_fix = config[15]\n",
    "xg_fix = config[16]\n",
    "if obs_fix:\n",
    "    obstacles = config[-1]\n",
    "\n",
    "config_fn = os.path.join(relative_path, 'config', dataset_name+'.p')#\n",
    "\n",
    "prob = MPC(config=config_fn)\n",
    "#create numpy containers for data: (params, x, u, y, J*, solve_time)\n",
    "params = {}\n",
    "if 'x0' in sampled_params:\n",
    "    params['x0'] = np.zeros((num_probs,2*n))\n",
    "if 'xg' in sampled_params:\n",
    "    params['xg'] = np.zeros((num_probs,2*n))\n",
    "if 'obstacles' in sampled_params:\n",
    "    params['obstacles'] = np.zeros((num_probs, 4, n_obs))\n",
    "\n",
    "X = np.zeros((num_probs, 2*n, N));\n",
    "U = np.zeros((num_probs, m, N-1))\n",
    "Y = np.zeros((num_probs, 4*n_obs, N-1)).astype(int)\n",
    "Z = np.zeros((num_probs, 2*n_obs, N-1)).astype(int)\n",
    "\n",
    "costs = np.zeros(num_probs)\n",
    "solve_times = np.zeros(num_probs)\n",
    "\n",
    "prob.sampled_params = ['x0', 'xg', 'obstacles']\n",
    "\n",
    "#solving MICP\n",
    "ii_toggle = 0\n",
    "obs_new_ct = 5\n",
    "ii=0\n",
    "obstacles = config[-1]\n",
    "\n",
    "if obs_fix:\n",
    "    for ii in tqdm(range(num_probs)):\n",
    "        x0 = findIC(obstacles, posmin, posmax, velmin, velmax)\n",
    "        params['obstacles'][ii,:] = np.reshape(np.concatenate(obstacles, axis=0), (n_obs,4)).T\n",
    "        p_dict = {}\n",
    "        params['x0'][ii,:] = x0\n",
    "        xg= findIC(obstacles, posmin, posmax, velmin, velmax)\n",
    "        params['xg'][ii,:] = xg\n",
    "\n",
    "        p_dict['x0'] = params['x0'][ii,:]\n",
    "        p_dict['xg'] = params['xg'][ii,:]\n",
    "        p_dict['obstacles'] = params['obstacles'][ii,:]\n",
    "\n",
    "        prob_success = False\n",
    "        try:\n",
    "            # with time_limit(20):\n",
    "            prob_success, cost, solve_time, optvals = prob.solve_stl(p_dict, solver=cp.GUROBI)\n",
    "        except (KeyboardInterrupt, SystemExit):\n",
    "            raise\n",
    "        except:\n",
    "            print('solver failed at '.format(ii))\n",
    "\n",
    "        if prob_success:\n",
    "            costs[ii] = cost; solve_times[ii] = solve_time\n",
    "            X[ii,:,:], U[ii,:,:], Y[ii,:,:], Z[ii,:,:] = optvals\n",
    "            ii += 1\n",
    "else:\n",
    "    print('choose to fix obstalce')\n",
    "\n",
    "## shuffle the data because of the spatial orders\n",
    "num_train = int(num_probs*0.9)\n",
    "arr = np.arange(num_probs)\n",
    "np.random.shuffle(arr)\n",
    "\n",
    "if 'x0' in sampled_params:\n",
    "    params['x0'] = params['x0'][arr]\n",
    "if 'xg' in sampled_params:\n",
    "    params['xg'] = params['xg'][arr]\n",
    "if 'obstacles' in sampled_params:\n",
    "    params['obstacles'] = params['obstacles'][arr]\n",
    "\n",
    "costs = costs[arr]\n",
    "solve_times = solve_times[arr]\n",
    "\n",
    "\n",
    "X = X[arr]\n",
    "U = U[arr]\n",
    "Y = Y[arr]\n",
    "Z = Z[arr]\n",
    "\n",
    "train_params = {}; test_params = {}\n",
    "if 'x0' in sampled_params:\n",
    "    train_params['x0'] = params['x0'][:num_train,:]\n",
    "    test_params['x0'] = params['x0'][num_train:,:]\n",
    "if 'obstacles' in sampled_params:\n",
    "    train_params['obstacles'] = params['obstacles'][:num_train,:]\n",
    "    test_params['obstacles'] = params['obstacles'][num_train:,:]\n",
    "if 'xg' in sampled_params:\n",
    "    train_params['xg'] = params['xg'][:num_train,:]\n",
    "    test_params['xg'] = params['xg'][num_train:,:]\n",
    "\n",
    "train_data = [train_params]\n",
    "train_data += [X[:num_train,:,:], U[:num_train,:,:], Y[:num_train,:,:],Z[:num_train,:,:]]\n",
    "train_data += [costs[:num_train], solve_times[:num_train]]\n",
    "\n",
    "test_data = [test_params]\n",
    "test_data += [X[num_train:,:,:], U[num_train:,:,:], Y[num_train:,:,:], Z[:num_train,:,:]]\n",
    "test_data += [costs[num_train:], solve_times[num_train:]]\n",
    "\n",
    "train_file = open(train_fn,'wb')\n",
    "pickle.dump(train_data,train_file); train_file.close()\n",
    "\n",
    "test_file = open(test_fn, 'wb')\n",
    "pickle.dump(test_data,test_file); test_file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "relative_path = os.getcwd()\n",
    "dataset_name = 'MPC_horizon_{}_obs_{}'.format(N,n_obs)\n",
    "# dataset_name = 'NSTL_{}_horizon_{}'.format(Qs, N)\n",
    "config_fn = os.path.join(relative_path, 'config', dataset_name+'.p')\n",
    "prob = MPC(config=config_fn) #use default config, pass different config file oth.\n",
    "\n",
    "relative_path = os.getcwd()\n",
    "dataset_fn = relative_path + '/data/' + dataset_name\n",
    "\n",
    "##load train data\n",
    "train_file = open(dataset_fn+'/train_horizon_{}.p'.format(N),'rb')\n",
    "# train_file = open(dataset_fn+'/train.p','rb')\n",
    "train_data = pickle.load(train_file)\n",
    "p_train, x_train, u_train, y_train, z_train, cost_train, times_train = train_data\n",
    "train_file.close()\n",
    "\n",
    "x_train = train_data[1] #X sequence\n",
    "y_train = train_data[3] #Y sequence\n",
    "\n",
    "##load test data\n",
    "test_file = open(dataset_fn+'/test_horizon_{}.p'.format(N),'rb')\n",
    "# test_file = open(dataset_fn+'/test.p','rb')\n",
    "# p_test, x_test, u_test, y_test, c_test, times_test = pickle.load(test_file)\n",
    "test_data = pickle.load(test_file)\n",
    "p_test, x_test, u_test, y_test,z_test, cost_test,times_test = test_data\n",
    "test_file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nubmber of strategies:2202\n",
      "n_obs: 5\n",
      "N: 10\n",
      "Loading presaved classifier model from D:\\Curious\\OMISTL\\models\\MPC_horizon_10_obs_5.pt\n"
     ]
    }
   ],
   "source": [
    "system = 'MPC'\n",
    "prob_features = ['x0','xg','obstacles']\n",
    "# prob_features = ['x0','obstacles_map']\n",
    "MPC_obj = OMISTL(system, prob, prob_features)\n",
    "\n",
    "# dimensions of features are 4(x0)+4(xg)+4*number_obstacles+n_obs(onehot_index)\n",
    "\n",
    "n_features = 2*prob.n*(len(prob_features)-1)+n_obs*4+n_obs\n",
    "MPC_obj.construct_strategies(n_features, train_data)\n",
    "print('nubmber of strategies:'+ str(MPC_obj.n_strategies))\n",
    "print('n_obs: '+ str(n_obs))\n",
    "print('N: '+ str(N))\n",
    "MPC_obj.n_evals\n",
    "MPC_obj.setup_network()\n",
    "fn_saved = 'D:\\Curious\\OMISTL\\\\models\\\\MPC_horizon_{}_obs_{}.pt'.format(N,n_obs)\n",
    "MPC_obj.load_network(fn_saved)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:   4.980214595794678,   acc:  0.3125\n",
      "loss:   3.3978090286254883,   acc:  0.375\n",
      "Done with epoch 0 in 13.799950361251831s\n",
      "loss:   3.5012383460998535,   acc:  0.3125\n",
      "loss:   3.7509822845458984,   acc:  0.25\n",
      "loss:   2.687976360321045,   acc:  0.5\n",
      "Done with epoch 1 in 11.445456981658936s\n",
      "loss:   3.197068452835083,   acc:  0.40625\n",
      "loss:   2.1897623538970947,   acc:  0.53125\n",
      "loss:   3.0660879611968994,   acc:  0.375\n",
      "Done with epoch 2 in 11.565070629119873s\n",
      "loss:   2.972336769104004,   acc:  0.3125\n",
      "loss:   2.8826279640197754,   acc:  0.3125\n",
      "loss:   2.652818441390991,   acc:  0.3125\n",
      "Done with epoch 3 in 11.672903776168823s\n",
      "loss:   2.158147096633911,   acc:  0.4375\n",
      "loss:   2.4542016983032227,   acc:  0.40625\n",
      "loss:   1.9619592428207397,   acc:  0.53125\n",
      "Done with epoch 4 in 11.845120668411255s\n",
      "loss:   1.8364193439483643,   acc:  0.5625\n",
      "loss:   2.380570650100708,   acc:  0.40625\n",
      "Done with epoch 5 in 11.378574848175049s\n",
      "loss:   2.058718681335449,   acc:  0.53125\n",
      "loss:   1.6917544603347778,   acc:  0.40625\n",
      "loss:   2.4641942977905273,   acc:  0.53125\n",
      "Done with epoch 6 in 11.764490127563477s\n",
      "loss:   2.3469059467315674,   acc:  0.40625\n",
      "loss:   2.375627040863037,   acc:  0.5\n",
      "loss:   1.8493140935897827,   acc:  0.4375\n",
      "Done with epoch 7 in 11.955430030822754s\n",
      "loss:   2.157776117324829,   acc:  0.46875\n",
      "loss:   1.9438799619674683,   acc:  0.5625\n",
      "loss:   1.5891447067260742,   acc:  0.53125\n",
      "Done with epoch 8 in 11.83430027961731s\n",
      "loss:   2.352257490158081,   acc:  0.375\n",
      "loss:   1.8945274353027344,   acc:  0.375\n",
      "loss:   1.6976392269134521,   acc:  0.5625\n",
      "Done with epoch 9 in 11.786328077316284s\n",
      "loss:   1.85634446144104,   acc:  0.46875\n",
      "loss:   1.8135535717010498,   acc:  0.4375\n",
      "Saved model at ../models\\MPC_horizon_12_obs_10.pt\n",
      "Done with epoch 10 in 12.079914331436157s\n",
      "loss:   1.7812267541885376,   acc:  0.5\n",
      "loss:   2.114504814147949,   acc:  0.4375\n",
      "loss:   1.8417832851409912,   acc:  0.4375\n",
      "Done with epoch 11 in 11.924063205718994s\n",
      "loss:   2.3788509368896484,   acc:  0.4375\n",
      "loss:   1.922848105430603,   acc:  0.40625\n",
      "loss:   1.8526498079299927,   acc:  0.53125\n",
      "Done with epoch 12 in 11.955589532852173s\n",
      "loss:   1.79871666431427,   acc:  0.5625\n",
      "loss:   1.5419856309890747,   acc:  0.625\n",
      "loss:   1.95870840549469,   acc:  0.53125\n",
      "Done with epoch 13 in 12.03232479095459s\n",
      "loss:   1.5001983642578125,   acc:  0.59375\n",
      "loss:   2.056391477584839,   acc:  0.5\n",
      "loss:   1.7511012554168701,   acc:  0.40625\n",
      "Done with epoch 14 in 12.034924030303955s\n",
      "loss:   1.3413517475128174,   acc:  0.59375\n",
      "loss:   1.6054905652999878,   acc:  0.65625\n",
      "loss:   1.9577304124832153,   acc:  0.4375\n",
      "Done with epoch 15 in 12.486137390136719s\n",
      "loss:   1.8237730264663696,   acc:  0.5\n",
      "loss:   1.2320380210876465,   acc:  0.71875\n",
      "Done with epoch 16 in 11.854363441467285s\n",
      "loss:   1.6187148094177246,   acc:  0.46875\n",
      "loss:   1.276160717010498,   acc:  0.625\n",
      "loss:   1.016784906387329,   acc:  0.65625\n",
      "Done with epoch 17 in 12.141672134399414s\n",
      "loss:   1.416593074798584,   acc:  0.5625\n",
      "loss:   2.2895450592041016,   acc:  0.5\n",
      "loss:   1.561909794807434,   acc:  0.5625\n",
      "Done with epoch 18 in 12.249699354171753s\n",
      "loss:   1.8963522911071777,   acc:  0.5\n",
      "loss:   1.849773645401001,   acc:  0.40625\n",
      "loss:   2.035205841064453,   acc:  0.375\n",
      "Done with epoch 19 in 12.141350746154785s\n",
      "loss:   1.5816917419433594,   acc:  0.59375\n",
      "loss:   1.9614005088806152,   acc:  0.34375\n",
      "loss:   1.8778810501098633,   acc:  0.4375\n",
      "Done with epoch 20 in 12.55287480354309s\n",
      "loss:   1.4075822830200195,   acc:  0.625\n",
      "Saved model at ../models\\MPC_horizon_12_obs_10.pt\n",
      "loss:   1.5067024230957031,   acc:  0.5625\n",
      "Done with epoch 21 in 12.112253904342651s\n",
      "loss:   2.076706886291504,   acc:  0.53125\n",
      "loss:   1.6503384113311768,   acc:  0.53125\n",
      "loss:   1.9396404027938843,   acc:  0.46875\n",
      "Done with epoch 22 in 12.143522024154663s\n",
      "loss:   1.971841812133789,   acc:  0.46875\n",
      "loss:   1.437948226928711,   acc:  0.53125\n",
      "loss:   1.551263689994812,   acc:  0.53125\n",
      "Done with epoch 23 in 12.206189393997192s\n",
      "loss:   1.4564602375030518,   acc:  0.5625\n",
      "loss:   1.3769409656524658,   acc:  0.625\n",
      "loss:   2.5741124153137207,   acc:  0.34375\n",
      "Done with epoch 24 in 12.206274032592773s\n",
      "loss:   1.464066505432129,   acc:  0.625\n",
      "loss:   1.5533424615859985,   acc:  0.59375\n",
      "loss:   1.5793495178222656,   acc:  0.5625\n",
      "Done with epoch 25 in 12.19052791595459s\n",
      "loss:   1.529261827468872,   acc:  0.59375\n",
      "loss:   1.0999269485473633,   acc:  0.6875\n",
      "Done with epoch 26 in 12.357860803604126s\n",
      "loss:   1.409814476966858,   acc:  0.59375\n",
      "loss:   1.0302035808563232,   acc:  0.6875\n",
      "loss:   1.3680262565612793,   acc:  0.625\n",
      "Done with epoch 27 in 12.141626358032227s\n",
      "loss:   1.4878145456314087,   acc:  0.5625\n",
      "loss:   1.442851185798645,   acc:  0.59375\n",
      "loss:   1.5101537704467773,   acc:  0.5625\n",
      "Done with epoch 28 in 14.032596826553345s\n",
      "loss:   1.2221109867095947,   acc:  0.6875\n",
      "loss:   1.4539289474487305,   acc:  0.59375\n",
      "loss:   2.1084718704223633,   acc:  0.4375\n",
      "Done with epoch 29 in 16.57969617843628s\n",
      "loss:   1.932145595550537,   acc:  0.53125\n",
      "loss:   1.4228317737579346,   acc:  0.59375\n",
      "loss:   1.663444995880127,   acc:  0.4375\n",
      "Done with epoch 30 in 16.757654905319214s\n",
      "loss:   1.267533779144287,   acc:  0.625\n",
      "loss:   1.184140920639038,   acc:  0.5625\n",
      "loss:   1.6651782989501953,   acc:  0.625\n",
      "Saved model at ../models\\MPC_horizon_12_obs_10.pt\n",
      "Done with epoch 31 in 16.798145055770874s\n",
      "loss:   1.3660467863082886,   acc:  0.59375\n",
      "loss:   0.7708118557929993,   acc:  0.75\n",
      "Done with epoch 32 in 16.208618879318237s\n",
      "loss:   1.4138834476470947,   acc:  0.625\n",
      "loss:   1.807326316833496,   acc:  0.5625\n",
      "loss:   1.1555938720703125,   acc:  0.71875\n",
      "Done with epoch 33 in 16.267520666122437s\n",
      "loss:   1.5090806484222412,   acc:  0.53125\n",
      "loss:   1.7143129110336304,   acc:  0.53125\n",
      "loss:   1.26437246799469,   acc:  0.6875\n",
      "Done with epoch 34 in 16.855101108551025s\n",
      "loss:   1.9668641090393066,   acc:  0.4375\n",
      "loss:   1.6501109600067139,   acc:  0.53125\n",
      "loss:   1.8067611455917358,   acc:  0.4375\n",
      "Done with epoch 35 in 16.517062187194824s\n",
      "loss:   1.5481164455413818,   acc:  0.5\n",
      "loss:   1.5557429790496826,   acc:  0.53125\n",
      "loss:   1.3798482418060303,   acc:  0.46875\n",
      "Done with epoch 36 in 16.267144918441772s\n",
      "loss:   1.4710805416107178,   acc:  0.65625\n",
      "loss:   1.370145559310913,   acc:  0.65625\n",
      "Done with epoch 37 in 16.220295667648315s\n",
      "loss:   0.6995956301689148,   acc:  0.84375\n",
      "loss:   0.9210137724876404,   acc:  0.6875\n",
      "loss:   1.560423731803894,   acc:  0.59375\n",
      "Done with epoch 38 in 16.543740272521973s\n",
      "loss:   1.983347773551941,   acc:  0.5\n",
      "loss:   1.5622522830963135,   acc:  0.59375\n",
      "loss:   1.9101016521453857,   acc:  0.5\n",
      "Done with epoch 39 in 16.50167751312256s\n",
      "loss:   1.7287836074829102,   acc:  0.53125\n",
      "loss:   1.6280858516693115,   acc:  0.46875\n",
      "loss:   1.3504478931427002,   acc:  0.625\n",
      "Done with epoch 40 in 16.45465064048767s\n",
      "loss:   1.6208999156951904,   acc:  0.53125\n",
      "loss:   1.7522451877593994,   acc:  0.59375\n",
      "loss:   1.5666877031326294,   acc:  0.625\n",
      "Done with epoch 41 in 16.184860229492188s\n",
      "loss:   1.0653316974639893,   acc:  0.75\n",
      "loss:   1.1683404445648193,   acc:  0.59375\n",
      "Saved model at ../models\\MPC_horizon_12_obs_10.pt\n",
      "Done with epoch 42 in 16.220282077789307s\n",
      "loss:   1.4043079614639282,   acc:  0.625\n",
      "loss:   1.7233997583389282,   acc:  0.375\n",
      "loss:   1.7315244674682617,   acc:  0.625\n",
      "Done with epoch 43 in 15.986178398132324s\n",
      "loss:   1.7188745737075806,   acc:  0.5\n",
      "loss:   1.3252938985824585,   acc:  0.6875\n",
      "loss:   1.2342432737350464,   acc:  0.6875\n",
      "Done with epoch 44 in 12.016420602798462s\n",
      "loss:   1.1718037128448486,   acc:  0.59375\n",
      "loss:   1.5444042682647705,   acc:  0.59375\n",
      "loss:   1.6342710256576538,   acc:  0.46875\n",
      "Done with epoch 45 in 11.935170650482178s\n",
      "loss:   1.2496998310089111,   acc:  0.53125\n",
      "loss:   1.6765819787979126,   acc:  0.5625\n",
      "loss:   0.7547712326049805,   acc:  0.75\n",
      "Done with epoch 46 in 12.114140510559082s\n",
      "loss:   1.234885334968567,   acc:  0.53125\n",
      "loss:   1.6154743432998657,   acc:  0.53125\n",
      "loss:   1.3347879648208618,   acc:  0.5625\n",
      "Done with epoch 47 in 12.204067945480347s\n",
      "loss:   1.5628612041473389,   acc:  0.53125\n",
      "loss:   1.354210376739502,   acc:  0.65625\n",
      "Done with epoch 48 in 12.235614776611328s\n",
      "loss:   1.6257330179214478,   acc:  0.5\n",
      "loss:   1.4945275783538818,   acc:  0.5625\n",
      "loss:   1.5517711639404297,   acc:  0.5\n",
      "Done with epoch 49 in 12.329038381576538s\n",
      "loss:   1.1921672821044922,   acc:  0.59375\n",
      "loss:   1.522935152053833,   acc:  0.46875\n",
      "loss:   1.475911259651184,   acc:  0.5625\n",
      "Done with epoch 50 in 12.255446910858154s\n",
      "loss:   1.1775264739990234,   acc:  0.625\n",
      "loss:   1.764334797859192,   acc:  0.65625\n",
      "loss:   1.2267496585845947,   acc:  0.625\n",
      "Done with epoch 51 in 12.153038740158081s\n",
      "loss:   1.8639519214630127,   acc:  0.53125\n",
      "loss:   1.5357446670532227,   acc:  0.53125\n",
      "loss:   1.2810419797897339,   acc:  0.65625\n",
      "Done with epoch 52 in 12.378190040588379s\n",
      "loss:   1.2047582864761353,   acc:  0.5625\n",
      "Saved model at ../models\\MPC_horizon_12_obs_10.pt\n",
      "loss:   1.8647849559783936,   acc:  0.40625\n",
      "Done with epoch 53 in 12.485706806182861s\n",
      "loss:   1.298462152481079,   acc:  0.53125\n",
      "loss:   1.249705195426941,   acc:  0.65625\n",
      "loss:   1.7252626419067383,   acc:  0.59375\n",
      "Done with epoch 54 in 12.173659801483154s\n",
      "loss:   1.7181657552719116,   acc:  0.4375\n",
      "loss:   1.165136456489563,   acc:  0.6875\n",
      "loss:   1.154690146446228,   acc:  0.59375\n",
      "Done with epoch 55 in 12.245380878448486s\n",
      "loss:   1.3379647731781006,   acc:  0.59375\n",
      "loss:   1.917871117591858,   acc:  0.5\n",
      "loss:   1.207289695739746,   acc:  0.59375\n",
      "Done with epoch 56 in 12.188816547393799s\n",
      "loss:   1.355682134628296,   acc:  0.53125\n",
      "loss:   1.3359159231185913,   acc:  0.59375\n",
      "loss:   0.9232678413391113,   acc:  0.6875\n",
      "Done with epoch 57 in 12.282274007797241s\n",
      "loss:   1.093865156173706,   acc:  0.65625\n",
      "loss:   1.3400616645812988,   acc:  0.59375\n",
      "Done with epoch 58 in 12.297901391983032s\n",
      "loss:   1.1164584159851074,   acc:  0.625\n",
      "loss:   1.9579055309295654,   acc:  0.5625\n",
      "loss:   1.4319345951080322,   acc:  0.625\n",
      "Done with epoch 59 in 12.266759872436523s\n",
      "loss:   1.4604506492614746,   acc:  0.46875\n",
      "loss:   1.1393704414367676,   acc:  0.65625\n",
      "loss:   1.2059563398361206,   acc:  0.59375\n",
      "Done with epoch 60 in 12.279839515686035s\n",
      "loss:   1.4588602781295776,   acc:  0.5625\n",
      "loss:   1.6182526350021362,   acc:  0.46875\n",
      "loss:   1.885061264038086,   acc:  0.53125\n",
      "Done with epoch 61 in 12.157231330871582s\n",
      "loss:   2.0362014770507812,   acc:  0.5\n",
      "loss:   1.0179176330566406,   acc:  0.59375\n",
      "loss:   1.38508939743042,   acc:  0.53125\n",
      "Done with epoch 62 in 12.672948360443115s\n",
      "loss:   1.5628583431243896,   acc:  0.5625\n",
      "loss:   1.5226720571517944,   acc:  0.5\n",
      "loss:   1.7743065357208252,   acc:  0.5\n",
      "Saved model at ../models\\MPC_horizon_12_obs_10.pt\n",
      "Done with epoch 63 in 12.157209634780884s\n",
      "loss:   1.4371216297149658,   acc:  0.5\n",
      "loss:   1.8625366687774658,   acc:  0.4375\n",
      "Done with epoch 64 in 12.329398393630981s\n",
      "loss:   1.374962568283081,   acc:  0.625\n",
      "loss:   1.024204134941101,   acc:  0.6875\n",
      "loss:   1.723304271697998,   acc:  0.53125\n",
      "Done with epoch 65 in 12.195768356323242s\n",
      "loss:   0.9495481848716736,   acc:  0.65625\n",
      "loss:   1.775065541267395,   acc:  0.625\n",
      "loss:   1.383662462234497,   acc:  0.5\n",
      "Done with epoch 66 in 12.32922649383545s\n",
      "loss:   1.148435115814209,   acc:  0.71875\n",
      "loss:   1.1624633073806763,   acc:  0.625\n",
      "loss:   1.2195980548858643,   acc:  0.65625\n",
      "Done with epoch 67 in 12.363291025161743s\n",
      "loss:   1.5973072052001953,   acc:  0.5\n",
      "loss:   1.5090528726577759,   acc:  0.625\n",
      "loss:   1.476026177406311,   acc:  0.59375\n",
      "Done with epoch 68 in 12.17310094833374s\n",
      "loss:   1.4184597730636597,   acc:  0.5625\n",
      "loss:   1.4063026905059814,   acc:  0.59375\n",
      "Done with epoch 69 in 12.670931339263916s\n",
      "loss:   1.4378875494003296,   acc:  0.625\n",
      "loss:   1.291355848312378,   acc:  0.65625\n",
      "loss:   1.1025421619415283,   acc:  0.75\n",
      "Done with epoch 70 in 12.181175947189331s\n",
      "loss:   0.8634177446365356,   acc:  0.75\n",
      "loss:   1.0895408391952515,   acc:  0.59375\n",
      "loss:   0.8809624314308167,   acc:  0.75\n",
      "Done with epoch 71 in 12.329724550247192s\n",
      "loss:   1.7238267660140991,   acc:  0.5\n",
      "loss:   1.078639268875122,   acc:  0.6875\n",
      "loss:   1.4263439178466797,   acc:  0.5\n",
      "Done with epoch 72 in 12.266576766967773s\n",
      "loss:   1.2387210130691528,   acc:  0.5\n",
      "loss:   1.2362723350524902,   acc:  0.5625\n",
      "loss:   1.520133137702942,   acc:  0.5625\n",
      "Done with epoch 73 in 12.282306432723999s\n",
      "loss:   1.0010699033737183,   acc:  0.65625\n",
      "loss:   1.2372674942016602,   acc:  0.625\n",
      "Saved model at ../models\\MPC_horizon_12_obs_10.pt\n",
      "Done with epoch 74 in 12.47007966041565s\n",
      "loss:   1.0552090406417847,   acc:  0.71875\n",
      "loss:   1.507735252380371,   acc:  0.625\n",
      "loss:   0.9001447558403015,   acc:  0.65625\n",
      "Done with epoch 75 in 12.461395025253296s\n",
      "loss:   2.389948606491089,   acc:  0.25\n",
      "loss:   1.2227245569229126,   acc:  0.65625\n",
      "loss:   1.467043161392212,   acc:  0.53125\n",
      "Done with epoch 76 in 12.37626338005066s\n",
      "loss:   1.0509530305862427,   acc:  0.6875\n",
      "loss:   0.9945389628410339,   acc:  0.71875\n",
      "loss:   0.9822016358375549,   acc:  0.75\n",
      "Done with epoch 77 in 12.219821214675903s\n",
      "loss:   1.1464693546295166,   acc:  0.59375\n",
      "loss:   0.98746258020401,   acc:  0.65625\n",
      "loss:   1.4135922193527222,   acc:  0.625\n",
      "Done with epoch 78 in 12.4385507106781s\n",
      "loss:   1.2722256183624268,   acc:  0.5625\n",
      "loss:   1.2010053396224976,   acc:  0.5625\n",
      "loss:   1.5152076482772827,   acc:  0.625\n",
      "Done with epoch 79 in 12.298214197158813s\n",
      "loss:   1.731284260749817,   acc:  0.5\n",
      "loss:   1.116265058517456,   acc:  0.59375\n",
      "Done with epoch 80 in 12.513197898864746s\n",
      "loss:   0.9362428784370422,   acc:  0.8125\n",
      "loss:   1.133254885673523,   acc:  0.59375\n",
      "loss:   1.807368278503418,   acc:  0.5625\n",
      "Done with epoch 81 in 12.157221555709839s\n",
      "loss:   1.4138391017913818,   acc:  0.625\n",
      "loss:   1.4505289793014526,   acc:  0.59375\n",
      "loss:   1.3432669639587402,   acc:  0.53125\n",
      "Done with epoch 82 in 12.298229455947876s\n",
      "loss:   1.0148217678070068,   acc:  0.625\n",
      "loss:   1.0901285409927368,   acc:  0.71875\n",
      "loss:   1.097748041152954,   acc:  0.625\n",
      "Done with epoch 83 in 12.250926971435547s\n",
      "loss:   0.9151872992515564,   acc:  0.71875\n",
      "loss:   1.4461145401000977,   acc:  0.5625\n",
      "loss:   1.2775588035583496,   acc:  0.625\n",
      "Done with epoch 84 in 12.27974009513855s\n",
      "loss:   1.2099552154541016,   acc:  0.65625\n",
      "Saved model at ../models\\MPC_horizon_12_obs_10.pt\n",
      "loss:   1.2688497304916382,   acc:  0.71875\n",
      "Done with epoch 85 in 12.455630779266357s\n",
      "loss:   1.3010578155517578,   acc:  0.59375\n",
      "loss:   1.8658443689346313,   acc:  0.46875\n",
      "loss:   1.0762300491333008,   acc:  0.65625\n",
      "Done with epoch 86 in 12.188558340072632s\n",
      "loss:   1.1767319440841675,   acc:  0.6875\n",
      "loss:   0.8327298760414124,   acc:  0.75\n",
      "loss:   1.2661832571029663,   acc:  0.53125\n",
      "Done with epoch 87 in 12.3918616771698s\n",
      "loss:   1.824414849281311,   acc:  0.5625\n",
      "loss:   1.5118768215179443,   acc:  0.625\n",
      "loss:   1.3365029096603394,   acc:  0.625\n",
      "Done with epoch 88 in 12.235607624053955s\n",
      "loss:   1.4363574981689453,   acc:  0.5625\n",
      "loss:   0.9704906940460205,   acc:  0.75\n",
      "loss:   1.4147523641586304,   acc:  0.5\n",
      "Done with epoch 89 in 12.256306648254395s\n",
      "loss:   0.9404458999633789,   acc:  0.6875\n",
      "loss:   1.5697976350784302,   acc:  0.625\n",
      "Done with epoch 90 in 12.313546180725098s\n",
      "loss:   1.411301851272583,   acc:  0.625\n",
      "loss:   2.0359625816345215,   acc:  0.46875\n",
      "loss:   1.0747060775756836,   acc:  0.75\n",
      "Done with epoch 91 in 12.470306873321533s\n",
      "loss:   1.0725325345993042,   acc:  0.71875\n",
      "loss:   1.2462915182113647,   acc:  0.5\n",
      "loss:   1.6987931728363037,   acc:  0.46875\n",
      "Done with epoch 92 in 12.26683497428894s\n",
      "loss:   1.1981499195098877,   acc:  0.59375\n",
      "loss:   1.0332838296890259,   acc:  0.6875\n",
      "loss:   1.357801914215088,   acc:  0.625\n",
      "Done with epoch 93 in 12.21999216079712s\n",
      "loss:   1.0561901330947876,   acc:  0.59375\n",
      "loss:   1.0999035835266113,   acc:  0.59375\n",
      "loss:   1.4831610918045044,   acc:  0.5625\n",
      "Done with epoch 94 in 12.289805173873901s\n",
      "loss:   1.752016305923462,   acc:  0.53125\n",
      "loss:   1.5939555168151855,   acc:  0.40625\n",
      "loss:   1.0252467393875122,   acc:  0.71875\n",
      "Saved model at ../models\\MPC_horizon_12_obs_10.pt\n",
      "Done with epoch 95 in 16.345253467559814s\n",
      "loss:   0.8066369295120239,   acc:  0.65625\n",
      "loss:   1.1609854698181152,   acc:  0.625\n",
      "Done with epoch 96 in 16.548394203186035s\n",
      "loss:   1.325944423675537,   acc:  0.5625\n",
      "loss:   0.8926260471343994,   acc:  0.71875\n",
      "loss:   0.8273202180862427,   acc:  0.6875\n",
      "Done with epoch 97 in 16.38065218925476s\n",
      "loss:   1.5831527709960938,   acc:  0.53125\n",
      "loss:   1.2426071166992188,   acc:  0.71875\n",
      "loss:   1.6264559030532837,   acc:  0.53125\n",
      "Done with epoch 98 in 16.321898221969604s\n",
      "loss:   1.2727071046829224,   acc:  0.71875\n",
      "loss:   1.4972033500671387,   acc:  0.59375\n",
      "loss:   1.5431863069534302,   acc:  0.5625\n",
      "Done with epoch 99 in 16.4091215133667s\n",
      "loss:   1.3064528703689575,   acc:  0.5625\n",
      "loss:   1.067597508430481,   acc:  0.5\n",
      "loss:   1.1766302585601807,   acc:  0.65625\n",
      "Done with epoch 100 in 16.251535892486572s\n",
      "loss:   1.512291431427002,   acc:  0.59375\n",
      "loss:   1.8941060304641724,   acc:  0.375\n",
      "Done with epoch 101 in 16.220110654830933s\n",
      "loss:   1.468978762626648,   acc:  0.4375\n",
      "loss:   1.2190035581588745,   acc:  0.5625\n",
      "loss:   1.767822265625,   acc:  0.5\n",
      "Done with epoch 102 in 16.324270725250244s\n",
      "loss:   1.3689396381378174,   acc:  0.59375\n",
      "loss:   1.100751280784607,   acc:  0.6875\n",
      "loss:   1.083656907081604,   acc:  0.71875\n",
      "Done with epoch 103 in 16.3921959400177s\n",
      "loss:   1.419378638267517,   acc:  0.59375\n",
      "loss:   1.5341846942901611,   acc:  0.5\n",
      "loss:   1.5118273496627808,   acc:  0.5625\n",
      "Done with epoch 104 in 16.29852795600891s\n",
      "loss:   0.8708142042160034,   acc:  0.78125\n",
      "loss:   1.1934609413146973,   acc:  0.59375\n",
      "loss:   1.503830075263977,   acc:  0.59375\n",
      "Done with epoch 105 in 16.30568027496338s\n",
      "loss:   0.8511559963226318,   acc:  0.8125\n",
      "loss:   1.5680162906646729,   acc:  0.5625\n",
      "Saved model at ../models\\MPC_horizon_12_obs_10.pt\n",
      "Done with epoch 106 in 15.814666032791138s\n",
      "loss:   0.9125083684921265,   acc:  0.71875\n",
      "loss:   1.2338613271713257,   acc:  0.6875\n",
      "loss:   1.1064094305038452,   acc:  0.71875\n",
      "Done with epoch 107 in 12.867040157318115s\n",
      "loss:   1.010034441947937,   acc:  0.65625\n",
      "loss:   1.5302914381027222,   acc:  0.53125\n",
      "loss:   0.748717188835144,   acc:  0.84375\n",
      "Done with epoch 108 in 12.422825813293457s\n",
      "loss:   1.3272358179092407,   acc:  0.6875\n",
      "loss:   1.4076366424560547,   acc:  0.6875\n",
      "loss:   0.832082986831665,   acc:  0.75\n",
      "Done with epoch 109 in 12.11042594909668s\n",
      "loss:   2.1130878925323486,   acc:  0.46875\n",
      "loss:   1.4639118909835815,   acc:  0.59375\n",
      "loss:   0.8186773061752319,   acc:  0.8125\n",
      "Done with epoch 110 in 12.1116042137146s\n",
      "loss:   1.2922388315200806,   acc:  0.65625\n",
      "loss:   1.1252789497375488,   acc:  0.59375\n",
      "loss:   1.1553007364273071,   acc:  0.65625\n",
      "Done with epoch 111 in 12.164371967315674s\n",
      "loss:   1.1529604196548462,   acc:  0.65625\n",
      "loss:   0.8805478811264038,   acc:  0.71875\n",
      "Done with epoch 112 in 11.969874620437622s\n",
      "loss:   1.8113616704940796,   acc:  0.5\n",
      "loss:   1.0440878868103027,   acc:  0.71875\n",
      "loss:   1.6492118835449219,   acc:  0.5625\n",
      "Done with epoch 113 in 12.516695737838745s\n",
      "loss:   1.9971333742141724,   acc:  0.4375\n",
      "loss:   1.1371549367904663,   acc:  0.71875\n",
      "loss:   1.4749103784561157,   acc:  0.53125\n",
      "Done with epoch 114 in 12.235275268554688s\n",
      "loss:   1.3342856168746948,   acc:  0.625\n",
      "loss:   1.6367167234420776,   acc:  0.5\n",
      "loss:   1.4905396699905396,   acc:  0.5625\n",
      "Done with epoch 115 in 12.17503309249878s\n",
      "loss:   1.529511570930481,   acc:  0.5625\n",
      "loss:   1.1025700569152832,   acc:  0.6875\n",
      "loss:   1.6774288415908813,   acc:  0.53125\n",
      "Done with epoch 116 in 12.266878604888916s\n",
      "loss:   1.0620378255844116,   acc:  0.75\n",
      "Saved model at ../models\\MPC_horizon_12_obs_10.pt\n",
      "loss:   1.2052044868469238,   acc:  0.65625\n",
      "Done with epoch 117 in 12.032350540161133s\n",
      "loss:   1.4377070665359497,   acc:  0.6875\n",
      "loss:   1.634276270866394,   acc:  0.5\n",
      "loss:   1.2864874601364136,   acc:  0.625\n",
      "Done with epoch 118 in 12.266640901565552s\n",
      "loss:   1.3552559614181519,   acc:  0.5\n",
      "loss:   1.2642803192138672,   acc:  0.625\n",
      "loss:   1.0229666233062744,   acc:  0.65625\n",
      "Done with epoch 119 in 12.469719648361206s\n",
      "loss:   1.3855348825454712,   acc:  0.46875\n",
      "loss:   1.405547857284546,   acc:  0.53125\n",
      "loss:   1.3216235637664795,   acc:  0.625\n",
      "Done with epoch 120 in 12.205700397491455s\n",
      "loss:   0.9744229316711426,   acc:  0.71875\n",
      "loss:   1.2080252170562744,   acc:  0.71875\n",
      "loss:   1.408313274383545,   acc:  0.5\n",
      "Done with epoch 121 in 12.320060014724731s\n",
      "loss:   1.5708348751068115,   acc:  0.5\n",
      "loss:   1.290488600730896,   acc:  0.5625\n",
      "Done with epoch 122 in 12.157255411148071s\n",
      "loss:   1.3577311038970947,   acc:  0.65625\n",
      "loss:   1.2142813205718994,   acc:  0.625\n",
      "loss:   1.5007692575454712,   acc:  0.5625\n",
      "Done with epoch 123 in 12.219648838043213s\n",
      "loss:   1.3982415199279785,   acc:  0.71875\n",
      "loss:   0.9241988658905029,   acc:  0.75\n",
      "loss:   1.1254117488861084,   acc:  0.625\n",
      "Done with epoch 124 in 12.705870628356934s\n",
      "loss:   1.429330825805664,   acc:  0.59375\n",
      "loss:   1.3897745609283447,   acc:  0.625\n",
      "loss:   1.2179274559020996,   acc:  0.625\n",
      "Done with epoch 125 in 12.141441583633423s\n",
      "loss:   0.7719986438751221,   acc:  0.6875\n",
      "loss:   1.3283954858779907,   acc:  0.59375\n",
      "loss:   1.2244232892990112,   acc:  0.59375\n",
      "Done with epoch 126 in 12.74606704711914s\n",
      "loss:   1.7576791048049927,   acc:  0.5\n",
      "loss:   0.7964886426925659,   acc:  0.71875\n",
      "loss:   1.7865924835205078,   acc:  0.625\n",
      "Saved model at ../models\\MPC_horizon_12_obs_10.pt\n",
      "Done with epoch 127 in 12.267215728759766s\n",
      "loss:   1.4435746669769287,   acc:  0.5625\n",
      "loss:   0.9657390117645264,   acc:  0.625\n",
      "Done with epoch 128 in 12.063611268997192s\n",
      "loss:   1.5170438289642334,   acc:  0.59375\n",
      "loss:   0.9544820785522461,   acc:  0.6875\n",
      "loss:   1.4111685752868652,   acc:  0.625\n",
      "Done with epoch 129 in 12.670372724533081s\n",
      "loss:   1.0338202714920044,   acc:  0.53125\n",
      "loss:   1.7721147537231445,   acc:  0.53125\n",
      "loss:   1.4552334547042847,   acc:  0.625\n",
      "Done with epoch 130 in 12.221677303314209s\n",
      "loss:   1.039405345916748,   acc:  0.71875\n",
      "loss:   1.4214386940002441,   acc:  0.59375\n",
      "loss:   1.2587541341781616,   acc:  0.5625\n",
      "Done with epoch 131 in 12.548086643218994s\n",
      "loss:   1.1573294401168823,   acc:  0.5625\n",
      "loss:   1.7103099822998047,   acc:  0.5625\n",
      "loss:   1.1215041875839233,   acc:  0.71875\n",
      "Done with epoch 132 in 12.282588958740234s\n",
      "loss:   0.8290925025939941,   acc:  0.78125\n",
      "loss:   1.2710459232330322,   acc:  0.5\n",
      "Done with epoch 133 in 12.094873189926147s\n",
      "loss:   1.3082679510116577,   acc:  0.5625\n",
      "loss:   1.263913631439209,   acc:  0.59375\n",
      "loss:   0.9723176956176758,   acc:  0.71875\n",
      "Done with epoch 134 in 12.350809097290039s\n",
      "loss:   1.1408106088638306,   acc:  0.59375\n",
      "loss:   1.3193663358688354,   acc:  0.5625\n",
      "loss:   1.6245430707931519,   acc:  0.59375\n",
      "Done with epoch 135 in 12.594902992248535s\n",
      "loss:   0.8833765983581543,   acc:  0.65625\n",
      "loss:   1.2003298997879028,   acc:  0.65625\n",
      "loss:   0.9521198272705078,   acc:  0.625\n",
      "Done with epoch 136 in 12.29106855392456s\n",
      "loss:   1.3558591604232788,   acc:  0.6875\n",
      "loss:   0.8945626020431519,   acc:  0.71875\n",
      "loss:   1.3877267837524414,   acc:  0.5\n",
      "Done with epoch 137 in 12.235376119613647s\n",
      "loss:   1.0596213340759277,   acc:  0.65625\n",
      "loss:   0.9239257574081421,   acc:  0.75\n",
      "Saved model at ../models\\MPC_horizon_12_obs_10.pt\n",
      "loss:   0.9304251670837402,   acc:  0.65625\n",
      "Done with epoch 138 in 12.266846656799316s\n",
      "loss:   1.2175666093826294,   acc:  0.625\n",
      "loss:   1.1611051559448242,   acc:  0.625\n",
      "Done with epoch 139 in 12.048120260238647s\n",
      "loss:   1.2511764764785767,   acc:  0.59375\n",
      "loss:   1.2349618673324585,   acc:  0.625\n",
      "loss:   1.55282461643219,   acc:  0.5625\n",
      "Done with epoch 140 in 12.68847393989563s\n",
      "loss:   1.068173885345459,   acc:  0.71875\n",
      "loss:   1.2777125835418701,   acc:  0.53125\n",
      "loss:   1.450303554534912,   acc:  0.53125\n",
      "Done with epoch 141 in 12.391602754592896s\n",
      "loss:   1.4284181594848633,   acc:  0.625\n",
      "loss:   1.1238795518875122,   acc:  0.59375\n",
      "loss:   1.1355735063552856,   acc:  0.5625\n",
      "Done with epoch 142 in 12.26667594909668s\n",
      "loss:   1.5465425252914429,   acc:  0.625\n",
      "loss:   0.9883403778076172,   acc:  0.75\n",
      "loss:   1.0819352865219116,   acc:  0.625\n",
      "Done with epoch 143 in 12.282357215881348s\n",
      "loss:   1.7534037828445435,   acc:  0.46875\n",
      "loss:   1.400320291519165,   acc:  0.59375\n",
      "Done with epoch 144 in 12.104854106903076s\n",
      "loss:   1.153889775276184,   acc:  0.71875\n",
      "loss:   1.2906051874160767,   acc:  0.625\n",
      "loss:   0.9547572135925293,   acc:  0.65625\n",
      "Done with epoch 145 in 12.736514806747437s\n",
      "loss:   0.9954363107681274,   acc:  0.6875\n",
      "loss:   1.3211040496826172,   acc:  0.53125\n",
      "loss:   1.4366049766540527,   acc:  0.53125\n",
      "Done with epoch 146 in 12.266581773757935s\n",
      "loss:   1.1895778179168701,   acc:  0.625\n",
      "loss:   1.3105456829071045,   acc:  0.53125\n",
      "loss:   0.9734776020050049,   acc:  0.75\n",
      "Done with epoch 147 in 12.298025846481323s\n",
      "loss:   1.023785948753357,   acc:  0.6875\n",
      "loss:   1.4079176187515259,   acc:  0.5625\n",
      "loss:   1.0895676612854004,   acc:  0.59375\n",
      "Done with epoch 148 in 13.850412130355835s\n",
      "loss:   1.2808008193969727,   acc:  0.53125\n",
      "Saved model at ../models\\MPC_horizon_12_obs_10.pt\n",
      "loss:   1.8989158868789673,   acc:  0.40625\n",
      "Done with epoch 149 in 12.102889060974121s\n",
      "loss:   1.3353066444396973,   acc:  0.625\n",
      "loss:   1.7891433238983154,   acc:  0.375\n",
      "loss:   1.488152265548706,   acc:  0.5625\n",
      "Done with epoch 150 in 12.408011674880981s\n",
      "loss:   1.0914337635040283,   acc:  0.65625\n",
      "loss:   1.43160080909729,   acc:  0.625\n",
      "loss:   1.0234438180923462,   acc:  0.6875\n",
      "Done with epoch 151 in 12.469886302947998s\n",
      "loss:   1.237938404083252,   acc:  0.65625\n",
      "loss:   1.1242249011993408,   acc:  0.75\n",
      "loss:   1.093512773513794,   acc:  0.6875\n",
      "Done with epoch 152 in 12.173319816589355s\n",
      "loss:   1.3303934335708618,   acc:  0.5625\n",
      "loss:   1.3115403652191162,   acc:  0.5625\n",
      "loss:   1.215428113937378,   acc:  0.6875\n",
      "Done with epoch 153 in 12.110478639602661s\n",
      "loss:   1.2725670337677002,   acc:  0.65625\n",
      "loss:   1.6757259368896484,   acc:  0.5625\n",
      "loss:   1.30250084400177,   acc:  0.5625\n",
      "Done with epoch 154 in 12.038707256317139s\n",
      "loss:   1.4092785120010376,   acc:  0.53125\n",
      "loss:   1.252539873123169,   acc:  0.625\n",
      "Done with epoch 155 in 11.735347509384155s\n",
      "loss:   1.3011772632598877,   acc:  0.625\n",
      "loss:   1.5672931671142578,   acc:  0.5625\n",
      "loss:   1.2610695362091064,   acc:  0.65625\n",
      "Done with epoch 156 in 12.267359256744385s\n",
      "loss:   1.1400730609893799,   acc:  0.71875\n",
      "loss:   1.3890893459320068,   acc:  0.5625\n",
      "loss:   1.1570323705673218,   acc:  0.71875\n",
      "Done with epoch 157 in 11.938695907592773s\n",
      "loss:   0.8550153970718384,   acc:  0.75\n",
      "loss:   1.5567576885223389,   acc:  0.5\n",
      "loss:   1.2464909553527832,   acc:  0.59375\n",
      "Done with epoch 158 in 11.798218011856079s\n",
      "loss:   1.2516512870788574,   acc:  0.5625\n",
      "loss:   0.7440052032470703,   acc:  0.75\n",
      "loss:   0.9285740852355957,   acc:  0.65625\n",
      "Saved model at ../models\\MPC_horizon_12_obs_10.pt\n",
      "Done with epoch 159 in 11.762134313583374s\n",
      "loss:   1.153214454650879,   acc:  0.65625\n",
      "loss:   1.1329929828643799,   acc:  0.65625\n",
      "Done with epoch 160 in 11.641638040542603s\n",
      "loss:   1.3178534507751465,   acc:  0.5625\n",
      "loss:   0.9650325775146484,   acc:  0.75\n",
      "loss:   0.9625351428985596,   acc:  0.65625\n",
      "Done with epoch 161 in 11.985572814941406s\n",
      "loss:   1.338217854499817,   acc:  0.5\n",
      "loss:   1.0845375061035156,   acc:  0.6875\n",
      "loss:   0.6812975406646729,   acc:  0.8125\n",
      "Done with epoch 162 in 11.875858068466187s\n",
      "loss:   1.3857471942901611,   acc:  0.625\n",
      "loss:   1.5454704761505127,   acc:  0.59375\n",
      "loss:   1.452141523361206,   acc:  0.6875\n",
      "Done with epoch 163 in 11.70418405532837s\n",
      "loss:   1.1682889461517334,   acc:  0.59375\n",
      "loss:   1.1156604290008545,   acc:  0.625\n",
      "loss:   1.6422146558761597,   acc:  0.46875\n",
      "Done with epoch 164 in 11.7309250831604s\n",
      "loss:   1.0628840923309326,   acc:  0.75\n",
      "loss:   0.8105487823486328,   acc:  0.8125\n",
      "Done with epoch 165 in 11.641690969467163s\n",
      "loss:   1.3210930824279785,   acc:  0.5625\n",
      "loss:   1.488154649734497,   acc:  0.625\n",
      "loss:   1.409201979637146,   acc:  0.53125\n",
      "Done with epoch 166 in 11.8145170211792s\n",
      "loss:   1.1648979187011719,   acc:  0.65625\n",
      "loss:   1.4896955490112305,   acc:  0.53125\n",
      "loss:   1.13238525390625,   acc:  0.65625\n",
      "Done with epoch 167 in 11.938494205474854s\n",
      "loss:   0.7466955184936523,   acc:  0.71875\n",
      "loss:   1.1827783584594727,   acc:  0.71875\n",
      "loss:   1.0293428897857666,   acc:  0.6875\n",
      "Done with epoch 168 in 11.672690868377686s\n",
      "loss:   1.552199125289917,   acc:  0.53125\n",
      "loss:   1.7086246013641357,   acc:  0.4375\n",
      "loss:   1.491517186164856,   acc:  0.5625\n",
      "Done with epoch 169 in 15.736278295516968s\n",
      "loss:   1.1673872470855713,   acc:  0.65625\n",
      "loss:   0.9852008819580078,   acc:  0.6875\n",
      "Saved model at ../models\\MPC_horizon_12_obs_10.pt\n",
      "loss:   1.0232210159301758,   acc:  0.65625\n",
      "Done with epoch 170 in 16.423073530197144s\n",
      "loss:   1.6411356925964355,   acc:  0.46875\n",
      "loss:   1.415168285369873,   acc:  0.5625\n",
      "Done with epoch 171 in 16.096707105636597s\n",
      "loss:   0.8765456676483154,   acc:  0.6875\n",
      "loss:   1.979475498199463,   acc:  0.40625\n",
      "loss:   1.3459439277648926,   acc:  0.625\n",
      "Done with epoch 172 in 16.379330158233643s\n",
      "loss:   1.0124070644378662,   acc:  0.6875\n",
      "loss:   1.2833478450775146,   acc:  0.625\n",
      "loss:   1.1228923797607422,   acc:  0.71875\n",
      "Done with epoch 173 in 16.345559120178223s\n",
      "loss:   0.9855523109436035,   acc:  0.625\n",
      "loss:   1.1927340030670166,   acc:  0.59375\n",
      "loss:   1.3091511726379395,   acc:  0.53125\n",
      "Done with epoch 174 in 16.407790184020996s\n",
      "loss:   1.1353685855865479,   acc:  0.71875\n",
      "loss:   1.2707021236419678,   acc:  0.625\n",
      "loss:   1.245295524597168,   acc:  0.6875\n",
      "Done with epoch 175 in 13.313665866851807s\n",
      "loss:   1.346304178237915,   acc:  0.59375\n",
      "loss:   1.2612903118133545,   acc:  0.59375\n",
      "Done with epoch 176 in 12.01668119430542s\n",
      "loss:   1.1873269081115723,   acc:  0.59375\n",
      "loss:   1.3887138366699219,   acc:  0.65625\n",
      "loss:   0.4220154285430908,   acc:  0.84375\n",
      "Done with epoch 177 in 11.781002044677734s\n",
      "loss:   1.560210943222046,   acc:  0.59375\n",
      "loss:   1.519768476486206,   acc:  0.59375\n",
      "loss:   0.8404099941253662,   acc:  0.75\n",
      "Done with epoch 178 in 11.79804539680481s\n",
      "loss:   1.1070398092269897,   acc:  0.65625\n",
      "loss:   1.007910966873169,   acc:  0.6875\n",
      "loss:   1.0269930362701416,   acc:  0.6875\n",
      "Done with epoch 179 in 11.813392162322998s\n",
      "loss:   1.0071349143981934,   acc:  0.65625\n",
      "loss:   1.4700891971588135,   acc:  0.5\n",
      "loss:   1.066612720489502,   acc:  0.6875\n",
      "Done with epoch 180 in 11.672723531723022s\n",
      "loss:   1.0659701824188232,   acc:  0.71875\n",
      "Saved model at ../models\\MPC_horizon_12_obs_10.pt\n",
      "loss:   1.1836974620819092,   acc:  0.71875\n",
      "Done with epoch 181 in 11.76669716835022s\n",
      "loss:   1.1365039348602295,   acc:  0.625\n",
      "loss:   1.0414327383041382,   acc:  0.65625\n",
      "loss:   0.9225163459777832,   acc:  0.65625\n",
      "Done with epoch 182 in 11.934019088745117s\n",
      "loss:   0.9565126895904541,   acc:  0.75\n",
      "loss:   1.2440025806427002,   acc:  0.5625\n",
      "loss:   1.4919712543487549,   acc:  0.625\n",
      "Done with epoch 183 in 11.672784805297852s\n",
      "loss:   1.3140578269958496,   acc:  0.59375\n",
      "loss:   1.5816900730133057,   acc:  0.5625\n",
      "loss:   1.2122528553009033,   acc:  0.6875\n",
      "Done with epoch 184 in 11.726486444473267s\n",
      "loss:   1.1792335510253906,   acc:  0.6875\n",
      "loss:   1.1697887182235718,   acc:  0.65625\n",
      "loss:   1.389172077178955,   acc:  0.625\n",
      "Done with epoch 185 in 11.672707557678223s\n",
      "loss:   0.9638285636901855,   acc:  0.625\n",
      "loss:   0.738551139831543,   acc:  0.84375\n",
      "loss:   1.125563621520996,   acc:  0.625\n",
      "Done with epoch 186 in 11.641521453857422s\n",
      "loss:   1.0294747352600098,   acc:  0.59375\n",
      "loss:   0.8954389095306396,   acc:  0.6875\n",
      "Done with epoch 187 in 11.85770058631897s\n",
      "loss:   1.009932041168213,   acc:  0.71875\n",
      "loss:   1.235985279083252,   acc:  0.65625\n",
      "loss:   1.1608006954193115,   acc:  0.59375\n",
      "Done with epoch 188 in 11.625807046890259s\n",
      "loss:   1.5594120025634766,   acc:  0.53125\n",
      "loss:   1.0029826164245605,   acc:  0.65625\n",
      "loss:   1.0304229259490967,   acc:  0.625\n",
      "Done with epoch 189 in 11.657490730285645s\n",
      "loss:   0.7274916172027588,   acc:  0.84375\n",
      "loss:   0.9482080936431885,   acc:  0.75\n",
      "loss:   1.3008217811584473,   acc:  0.5625\n",
      "Done with epoch 190 in 11.641667366027832s\n",
      "loss:   1.2293035984039307,   acc:  0.5625\n",
      "loss:   0.7210450172424316,   acc:  0.75\n",
      "loss:   1.2319064140319824,   acc:  0.59375\n",
      "Saved model at ../models\\MPC_horizon_12_obs_10.pt\n",
      "Done with epoch 191 in 11.594743013381958s\n",
      "loss:   1.2090823650360107,   acc:  0.6875\n",
      "loss:   1.1379742622375488,   acc:  0.75\n",
      "Done with epoch 192 in 11.466384410858154s\n",
      "loss:   1.4816594123840332,   acc:  0.59375\n",
      "loss:   1.228438377380371,   acc:  0.53125\n",
      "loss:   1.1115803718566895,   acc:  0.625\n",
      "Done with epoch 193 in 12.460606098175049s\n",
      "loss:   1.362701654434204,   acc:  0.6875\n",
      "loss:   0.77705979347229,   acc:  0.6875\n",
      "loss:   1.2088775634765625,   acc:  0.59375\n",
      "Done with epoch 194 in 11.76703929901123s\n",
      "loss:   1.4806768894195557,   acc:  0.625\n",
      "loss:   0.8978452682495117,   acc:  0.625\n",
      "loss:   0.8508846759796143,   acc:  0.78125\n",
      "Done with epoch 195 in 11.735862731933594s\n",
      "loss:   1.0833728313446045,   acc:  0.59375\n",
      "loss:   1.0621750354766846,   acc:  0.65625\n",
      "loss:   1.9048030376434326,   acc:  0.40625\n",
      "Done with epoch 196 in 11.673866271972656s\n",
      "loss:   0.8131701946258545,   acc:  0.71875\n",
      "loss:   1.3723211288452148,   acc:  0.625\n",
      "Done with epoch 197 in 11.455145120620728s\n",
      "loss:   0.9586038589477539,   acc:  0.59375\n",
      "loss:   0.9332506656646729,   acc:  0.8125\n",
      "loss:   1.7195484638214111,   acc:  0.46875\n",
      "Done with epoch 198 in 11.866363525390625s\n",
      "loss:   1.2141408920288086,   acc:  0.59375\n",
      "loss:   0.8556420803070068,   acc:  0.71875\n",
      "loss:   1.557884931564331,   acc:  0.5625\n",
      "Done with epoch 199 in 11.657320261001587s\n",
      "loss:   1.136359453201294,   acc:  0.65625\n",
      "loss:   1.353877305984497,   acc:  0.625\n",
      "loss:   1.2283835411071777,   acc:  0.53125\n",
      "Done with epoch 200 in 11.641510963439941s\n",
      "loss:   0.9963514804840088,   acc:  0.625\n",
      "loss:   1.6312251091003418,   acc:  0.5\n",
      "loss:   1.8748557567596436,   acc:  0.4375\n",
      "Done with epoch 201 in 11.610376596450806s\n",
      "loss:   1.528641939163208,   acc:  0.5625\n",
      "loss:   0.8937795162200928,   acc:  0.78125\n",
      "Saved model at ../models\\MPC_horizon_12_obs_10.pt\n",
      "loss:   1.0580132007598877,   acc:  0.71875\n",
      "Done with epoch 202 in 11.55606985092163s\n",
      "loss:   0.8527309894561768,   acc:  0.71875\n",
      "loss:   1.257643222808838,   acc:  0.65625\n",
      "Done with epoch 203 in 11.432322025299072s\n",
      "loss:   0.5358779430389404,   acc:  0.84375\n",
      "loss:   1.2990028858184814,   acc:  0.6875\n",
      "loss:   0.6580822467803955,   acc:  0.71875\n",
      "Done with epoch 204 in 11.907299280166626s\n",
      "loss:   1.608201265335083,   acc:  0.53125\n",
      "loss:   1.209580898284912,   acc:  0.6875\n",
      "loss:   1.1437945365905762,   acc:  0.5625\n",
      "Done with epoch 205 in 11.469964742660522s\n",
      "loss:   0.9438302516937256,   acc:  0.6875\n",
      "loss:   1.6571857929229736,   acc:  0.5625\n",
      "loss:   0.9810476303100586,   acc:  0.75\n",
      "Done with epoch 206 in 11.579205989837646s\n",
      "loss:   1.4797136783599854,   acc:  0.5625\n",
      "loss:   1.0307767391204834,   acc:  0.65625\n",
      "loss:   0.8346667289733887,   acc:  0.71875\n",
      "Done with epoch 207 in 11.548379182815552s\n",
      "loss:   0.9540774822235107,   acc:  0.78125\n",
      "loss:   1.239866018295288,   acc:  0.625\n",
      "Done with epoch 208 in 11.393528699874878s\n",
      "loss:   0.9497616291046143,   acc:  0.6875\n",
      "loss:   0.8525826930999756,   acc:  0.75\n",
      "loss:   1.071455955505371,   acc:  0.6875\n",
      "Done with epoch 209 in 11.611385822296143s\n",
      "loss:   1.1466608047485352,   acc:  0.65625\n",
      "loss:   0.9331841468811035,   acc:  0.71875\n",
      "loss:   1.2334837913513184,   acc:  0.59375\n",
      "Done with epoch 210 in 11.922654867172241s\n",
      "loss:   0.9442322254180908,   acc:  0.6875\n",
      "loss:   1.352001428604126,   acc:  0.5625\n",
      "loss:   1.3881046772003174,   acc:  0.65625\n",
      "Done with epoch 211 in 11.610605239868164s\n",
      "loss:   1.488544225692749,   acc:  0.5\n",
      "loss:   1.0878489017486572,   acc:  0.65625\n",
      "loss:   1.290740966796875,   acc:  0.625\n",
      "Done with epoch 212 in 11.61027216911316s\n",
      "loss:   1.1289255619049072,   acc:  0.65625\n",
      "Saved model at ../models\\MPC_horizon_12_obs_10.pt\n",
      "loss:   1.5403306484222412,   acc:  0.5\n",
      "Done with epoch 213 in 11.367883920669556s\n",
      "loss:   1.0515611171722412,   acc:  0.75\n",
      "loss:   1.6171939373016357,   acc:  0.59375\n",
      "loss:   0.772813081741333,   acc:  0.78125\n",
      "Done with epoch 214 in 11.625994443893433s\n",
      "loss:   1.0799462795257568,   acc:  0.65625\n",
      "loss:   1.331432580947876,   acc:  0.59375\n",
      "loss:   0.8021132946014404,   acc:  0.71875\n",
      "Done with epoch 215 in 11.970258951187134s\n",
      "loss:   1.0401887893676758,   acc:  0.71875\n",
      "loss:   0.9769322872161865,   acc:  0.75\n",
      "loss:   1.3962242603302002,   acc:  0.625\n",
      "Done with epoch 216 in 11.563557863235474s\n",
      "loss:   0.8492765426635742,   acc:  0.65625\n",
      "loss:   1.29744553565979,   acc:  0.5\n",
      "loss:   1.1980726718902588,   acc:  0.71875\n",
      "Done with epoch 217 in 11.532345056533813s\n",
      "loss:   1.8786745071411133,   acc:  0.53125\n",
      "loss:   0.9875473976135254,   acc:  0.65625\n",
      "loss:   1.4065954685211182,   acc:  0.5\n",
      "Done with epoch 218 in 11.50011920928955s\n",
      "loss:   1.2791178226470947,   acc:  0.625\n",
      "loss:   1.5020301342010498,   acc:  0.53125\n",
      "Done with epoch 219 in 12.016724586486816s\n",
      "loss:   1.0671191215515137,   acc:  0.65625\n",
      "loss:   1.2633144855499268,   acc:  0.65625\n",
      "loss:   0.837566614151001,   acc:  0.6875\n",
      "Done with epoch 220 in 11.548120498657227s\n",
      "loss:   1.1870276927947998,   acc:  0.5625\n",
      "loss:   0.8165850639343262,   acc:  0.65625\n",
      "loss:   1.8777761459350586,   acc:  0.5625\n",
      "Done with epoch 221 in 11.92308521270752s\n",
      "loss:   1.0826096534729004,   acc:  0.6875\n",
      "loss:   1.2008605003356934,   acc:  0.6875\n",
      "loss:   0.9538729190826416,   acc:  0.6875\n",
      "Done with epoch 222 in 11.500861883163452s\n",
      "loss:   1.5857117176055908,   acc:  0.59375\n",
      "loss:   1.3552191257476807,   acc:  0.59375\n",
      "loss:   1.2996249198913574,   acc:  0.625\n",
      "Saved model at ../models\\MPC_horizon_12_obs_10.pt\n",
      "Done with epoch 223 in 11.548457384109497s\n",
      "loss:   1.4824316501617432,   acc:  0.53125\n",
      "loss:   1.2511186599731445,   acc:  0.625\n",
      "Done with epoch 224 in 11.485461473464966s\n",
      "loss:   1.20660400390625,   acc:  0.625\n",
      "loss:   1.0167832374572754,   acc:  0.625\n",
      "loss:   1.040595293045044,   acc:  0.625\n",
      "Done with epoch 225 in 11.500881910324097s\n",
      "loss:   1.3274521827697754,   acc:  0.6875\n",
      "loss:   1.1283831596374512,   acc:  0.625\n",
      "loss:   1.1109366416931152,   acc:  0.65625\n",
      "Done with epoch 226 in 11.641612529754639s\n",
      "loss:   0.9899806976318359,   acc:  0.78125\n",
      "loss:   1.3953020572662354,   acc:  0.53125\n",
      "loss:   1.2953100204467773,   acc:  0.65625\n",
      "Done with epoch 227 in 11.876349687576294s\n",
      "loss:   1.0707733631134033,   acc:  0.625\n",
      "loss:   1.140843391418457,   acc:  0.6875\n",
      "loss:   1.0235271453857422,   acc:  0.6875\n",
      "Done with epoch 228 in 11.592267513275146s\n",
      "loss:   0.9273719787597656,   acc:  0.71875\n",
      "loss:   1.5784361362457275,   acc:  0.46875\n",
      "Done with epoch 229 in 11.402594327926636s\n",
      "loss:   1.6276659965515137,   acc:  0.53125\n",
      "loss:   0.9077901840209961,   acc:  0.6875\n",
      "loss:   1.3314898014068604,   acc:  0.5625\n",
      "Done with epoch 230 in 11.62621283531189s\n",
      "loss:   0.8576345443725586,   acc:  0.75\n",
      "loss:   1.322211742401123,   acc:  0.5625\n",
      "loss:   1.7227859497070312,   acc:  0.53125\n",
      "Done with epoch 231 in 11.610458135604858s\n",
      "loss:   1.73569655418396,   acc:  0.5625\n",
      "loss:   1.1813278198242188,   acc:  0.6875\n",
      "loss:   0.9879186153411865,   acc:  0.65625\n",
      "Done with epoch 232 in 12.001089334487915s\n",
      "loss:   1.0257046222686768,   acc:  0.6875\n",
      "loss:   1.2380449771881104,   acc:  0.65625\n",
      "loss:   1.11020827293396,   acc:  0.71875\n",
      "Done with epoch 233 in 11.512362718582153s\n",
      "loss:   0.9697253704071045,   acc:  0.6875\n",
      "loss:   1.352015495300293,   acc:  0.625\n",
      "Saved model at ../models\\MPC_horizon_12_obs_10.pt\n",
      "loss:   1.0501220226287842,   acc:  0.65625\n",
      "Done with epoch 234 in 11.469595193862915s\n",
      "loss:   1.348130464553833,   acc:  0.53125\n",
      "loss:   1.0037028789520264,   acc:  0.625\n",
      "Done with epoch 235 in 11.422898292541504s\n",
      "loss:   1.5392708778381348,   acc:  0.5625\n",
      "loss:   0.9709138870239258,   acc:  0.6875\n",
      "loss:   1.1443698406219482,   acc:  0.65625\n",
      "Done with epoch 236 in 11.500866174697876s\n",
      "loss:   0.8881230354309082,   acc:  0.6875\n",
      "loss:   0.8006424903869629,   acc:  0.8125\n",
      "loss:   0.7194085121154785,   acc:  0.78125\n",
      "Done with epoch 237 in 11.501254558563232s\n",
      "loss:   1.1977171897888184,   acc:  0.71875\n",
      "loss:   0.7452867031097412,   acc:  0.78125\n",
      "loss:   1.127549648284912,   acc:  0.625\n",
      "Done with epoch 238 in 11.929155826568604s\n",
      "loss:   1.4160449504852295,   acc:  0.65625\n",
      "loss:   1.0082237720489502,   acc:  0.71875\n",
      "loss:   1.177673578262329,   acc:  0.625\n",
      "Done with epoch 239 in 11.563623428344727s\n",
      "loss:   1.2426800727844238,   acc:  0.59375\n",
      "loss:   0.9921374320983887,   acc:  0.78125\n",
      "Done with epoch 240 in 13.03233003616333s\n",
      "loss:   1.35935378074646,   acc:  0.59375\n",
      "loss:   1.1720623970031738,   acc:  0.625\n",
      "loss:   1.2126832008361816,   acc:  0.59375\n",
      "Done with epoch 241 in 17.361151695251465s\n",
      "loss:   0.7521109580993652,   acc:  0.75\n",
      "loss:   1.086940050125122,   acc:  0.6875\n",
      "loss:   1.0463299751281738,   acc:  0.71875\n",
      "Done with epoch 242 in 15.954466581344604s\n",
      "loss:   1.521998405456543,   acc:  0.5\n",
      "loss:   0.5899479389190674,   acc:  0.8125\n",
      "loss:   1.115177869796753,   acc:  0.59375\n",
      "Done with epoch 243 in 16.18218445777893s\n",
      "loss:   1.295788288116455,   acc:  0.5625\n",
      "loss:   1.1493957042694092,   acc:  0.65625\n",
      "loss:   1.1843643188476562,   acc:  0.6875\n",
      "Done with epoch 244 in 16.023637533187866s\n",
      "loss:   0.8759613037109375,   acc:  0.75\n",
      "Saved model at ../models\\MPC_horizon_12_obs_10.pt\n",
      "loss:   1.3372070789337158,   acc:  0.625\n",
      "Done with epoch 245 in 15.93876028060913s\n",
      "loss:   1.622718334197998,   acc:  0.53125\n",
      "loss:   0.7091002464294434,   acc:  0.8125\n",
      "loss:   1.196540117263794,   acc:  0.625\n",
      "Done with epoch 246 in 16.11056661605835s\n",
      "loss:   1.6021654605865479,   acc:  0.53125\n",
      "loss:   0.888817548751831,   acc:  0.8125\n",
      "loss:   1.4435310363769531,   acc:  0.5\n",
      "Done with epoch 247 in 16.20450448989868s\n",
      "loss:   1.188624620437622,   acc:  0.6875\n",
      "loss:   1.2493786811828613,   acc:  0.65625\n",
      "loss:   1.624976634979248,   acc:  0.59375\n",
      "Done with epoch 248 in 16.03264617919922s\n",
      "loss:   1.4329814910888672,   acc:  0.4375\n",
      "loss:   1.080599069595337,   acc:  0.625\n",
      "loss:   1.1860523223876953,   acc:  0.625\n",
      "Done with epoch 249 in 16.34495735168457s\n",
      "loss:   1.0768132209777832,   acc:  0.65625\n",
      "loss:   1.4849507808685303,   acc:  0.59375\n",
      "loss:   0.6966674327850342,   acc:  0.8125\n",
      "Done with epoch 250 in 16.075035572052002s\n",
      "loss:   1.427767038345337,   acc:  0.53125\n",
      "loss:   1.4067447185516357,   acc:  0.65625\n",
      "Done with epoch 251 in 16.18907928466797s\n",
      "loss:   1.4113104343414307,   acc:  0.59375\n",
      "loss:   1.053875207901001,   acc:  0.78125\n",
      "loss:   0.8915090560913086,   acc:  0.71875\n",
      "Done with epoch 252 in 16.032652139663696s\n",
      "loss:   1.16310715675354,   acc:  0.5625\n",
      "loss:   1.1171348094940186,   acc:  0.65625\n",
      "loss:   1.2001292705535889,   acc:  0.5625\n",
      "Done with epoch 253 in 16.37643051147461s\n",
      "loss:   1.4032912254333496,   acc:  0.59375\n",
      "loss:   1.1836214065551758,   acc:  0.71875\n",
      "loss:   1.3814067840576172,   acc:  0.625\n",
      "Done with epoch 254 in 16.014713287353516s\n",
      "loss:   1.0260653495788574,   acc:  0.625\n",
      "loss:   1.2531194686889648,   acc:  0.59375\n",
      "loss:   1.1256706714630127,   acc:  0.625\n",
      "Saved model at ../models\\MPC_horizon_12_obs_10.pt\n",
      "Done with epoch 255 in 16.485914707183838s\n",
      "loss:   1.085909128189087,   acc:  0.6875\n",
      "loss:   1.677788496017456,   acc:  0.53125\n",
      "Done with epoch 256 in 15.891850709915161s\n",
      "loss:   1.1912775039672852,   acc:  0.65625\n",
      "loss:   1.3841862678527832,   acc:  0.625\n",
      "loss:   1.2406139373779297,   acc:  0.625\n",
      "Done with epoch 257 in 16.163912296295166s\n",
      "loss:   0.885333776473999,   acc:  0.625\n",
      "loss:   1.1322879791259766,   acc:  0.65625\n",
      "loss:   1.3580694198608398,   acc:  0.5625\n",
      "Done with epoch 258 in 16.14181876182556s\n",
      "loss:   1.209320068359375,   acc:  0.625\n",
      "loss:   1.0256328582763672,   acc:  0.625\n",
      "loss:   1.3678598403930664,   acc:  0.46875\n",
      "Done with epoch 259 in 16.50182580947876s\n",
      "loss:   0.9985549449920654,   acc:  0.71875\n",
      "loss:   1.0720696449279785,   acc:  0.59375\n",
      "loss:   1.2017953395843506,   acc:  0.625\n",
      "Done with epoch 260 in 16.32971739768982s\n",
      "loss:   1.6546247005462646,   acc:  0.53125\n",
      "loss:   1.255511999130249,   acc:  0.59375\n",
      "loss:   1.1177465915679932,   acc:  0.625\n",
      "Done with epoch 261 in 16.371077299118042s\n",
      "loss:   1.0452921390533447,   acc:  0.65625\n",
      "loss:   1.2669305801391602,   acc:  0.65625\n",
      "Done with epoch 262 in 16.147693157196045s\n",
      "loss:   1.2127013206481934,   acc:  0.59375\n",
      "loss:   1.121100902557373,   acc:  0.71875\n",
      "loss:   1.2973251342773438,   acc:  0.65625\n",
      "Done with epoch 263 in 16.392331838607788s\n",
      "loss:   0.9950332641601562,   acc:  0.71875\n",
      "loss:   0.7242531776428223,   acc:  0.71875\n",
      "loss:   1.0814599990844727,   acc:  0.625\n",
      "Done with epoch 264 in 16.423314094543457s\n",
      "loss:   1.3957643508911133,   acc:  0.46875\n",
      "loss:   1.0939173698425293,   acc:  0.5625\n",
      "loss:   1.0104939937591553,   acc:  0.65625\n",
      "Done with epoch 265 in 16.195037364959717s\n",
      "loss:   1.071410894393921,   acc:  0.625\n",
      "loss:   1.36773681640625,   acc:  0.5\n",
      "Saved model at ../models\\MPC_horizon_12_obs_10.pt\n",
      "loss:   1.1879591941833496,   acc:  0.625\n",
      "Done with epoch 266 in 16.486220598220825s\n",
      "loss:   0.7640039920806885,   acc:  0.78125\n",
      "loss:   1.153778314590454,   acc:  0.6875\n",
      "Done with epoch 267 in 16.189019203186035s\n",
      "loss:   1.0081067085266113,   acc:  0.71875\n",
      "loss:   0.8137447834014893,   acc:  0.75\n",
      "loss:   1.3624334335327148,   acc:  0.59375\n",
      "Done with epoch 268 in 16.168485641479492s\n",
      "loss:   1.00142502784729,   acc:  0.6875\n",
      "loss:   1.254110336303711,   acc:  0.625\n",
      "loss:   1.100459337234497,   acc:  0.59375\n",
      "Done with epoch 269 in 16.08642077445984s\n",
      "loss:   1.4476642608642578,   acc:  0.6875\n",
      "loss:   0.9677345752716064,   acc:  0.65625\n",
      "loss:   1.0948517322540283,   acc:  0.59375\n",
      "Done with epoch 270 in 16.17362880706787s\n",
      "loss:   1.5934107303619385,   acc:  0.53125\n",
      "loss:   1.399221420288086,   acc:  0.625\n",
      "loss:   0.5635740756988525,   acc:  0.8125\n",
      "Done with epoch 271 in 16.220234394073486s\n",
      "loss:   1.1156377792358398,   acc:  0.625\n",
      "loss:   1.0123794078826904,   acc:  0.625\n",
      "Done with epoch 272 in 16.147151231765747s\n",
      "loss:   0.79374098777771,   acc:  0.71875\n",
      "loss:   0.770916223526001,   acc:  0.84375\n",
      "loss:   1.0720946788787842,   acc:  0.71875\n",
      "Done with epoch 273 in 16.07947301864624s\n",
      "loss:   1.0513157844543457,   acc:  0.65625\n",
      "loss:   1.0665106773376465,   acc:  0.65625\n",
      "loss:   1.2799081802368164,   acc:  0.5625\n",
      "Done with epoch 274 in 16.086609601974487s\n",
      "loss:   1.427640676498413,   acc:  0.5\n",
      "loss:   0.9372720718383789,   acc:  0.78125\n",
      "loss:   0.8147575855255127,   acc:  0.6875\n",
      "Done with epoch 275 in 16.59533190727234s\n",
      "loss:   1.3968427181243896,   acc:  0.53125\n",
      "loss:   1.6191048622131348,   acc:  0.5625\n",
      "loss:   1.4883153438568115,   acc:  0.65625\n",
      "Done with epoch 276 in 16.28263211250305s\n",
      "loss:   1.2353487014770508,   acc:  0.625\n",
      "Saved model at ../models\\MPC_horizon_12_obs_10.pt\n",
      "loss:   1.8039188385009766,   acc:  0.53125\n",
      "loss:   1.3790850639343262,   acc:  0.5\n",
      "Done with epoch 277 in 13.766936302185059s\n",
      "loss:   1.1955361366271973,   acc:  0.625\n",
      "loss:   1.438523530960083,   acc:  0.59375\n",
      "Done with epoch 278 in 11.657425880432129s\n",
      "loss:   0.8985989093780518,   acc:  0.75\n",
      "loss:   1.1579599380493164,   acc:  0.65625\n",
      "loss:   1.5495870113372803,   acc:  0.59375\n",
      "Done with epoch 279 in 11.907332420349121s\n",
      "loss:   1.038137674331665,   acc:  0.625\n",
      "loss:   0.9425063133239746,   acc:  0.65625\n",
      "loss:   1.2390904426574707,   acc:  0.5625\n",
      "Done with epoch 280 in 12.297940731048584s\n",
      "loss:   1.4561138153076172,   acc:  0.46875\n",
      "loss:   1.313633680343628,   acc:  0.5625\n",
      "loss:   1.2999143600463867,   acc:  0.625\n",
      "Done with epoch 281 in 11.750019073486328s\n",
      "loss:   1.081390142440796,   acc:  0.6875\n",
      "loss:   1.4895670413970947,   acc:  0.59375\n",
      "loss:   1.6192574501037598,   acc:  0.53125\n",
      "Done with epoch 282 in 11.704224824905396s\n",
      "loss:   1.3951942920684814,   acc:  0.65625\n",
      "loss:   1.0560901165008545,   acc:  0.6875\n",
      "Done with epoch 283 in 11.454588651657104s\n",
      "loss:   1.3191158771514893,   acc:  0.59375\n",
      "loss:   1.526787519454956,   acc:  0.5\n",
      "loss:   0.9944322109222412,   acc:  0.6875\n",
      "Done with epoch 284 in 11.71979546546936s\n",
      "loss:   1.1283679008483887,   acc:  0.65625\n",
      "loss:   0.9289882183074951,   acc:  0.75\n",
      "loss:   0.7958922386169434,   acc:  0.71875\n",
      "Done with epoch 285 in 11.719849586486816s\n",
      "loss:   1.5624275207519531,   acc:  0.5625\n",
      "loss:   1.6430721282958984,   acc:  0.46875\n",
      "loss:   1.3934299945831299,   acc:  0.5625\n",
      "Done with epoch 286 in 12.033446311950684s\n",
      "loss:   1.0785093307495117,   acc:  0.625\n",
      "loss:   0.8454182147979736,   acc:  0.71875\n",
      "loss:   1.5979199409484863,   acc:  0.5625\n",
      "Saved model at ../models\\MPC_horizon_12_obs_10.pt\n",
      "Done with epoch 287 in 11.61061143875122s\n",
      "loss:   1.032456874847412,   acc:  0.59375\n",
      "loss:   0.8269026279449463,   acc:  0.71875\n",
      "Done with epoch 288 in 11.469894409179688s\n",
      "loss:   1.2615766525268555,   acc:  0.59375\n",
      "loss:   1.0991487503051758,   acc:  0.625\n",
      "loss:   1.5312294960021973,   acc:  0.59375\n",
      "Done with epoch 289 in 11.563551425933838s\n",
      "loss:   1.7896242141723633,   acc:  0.5\n",
      "loss:   1.0377013683319092,   acc:  0.6875\n",
      "loss:   0.9210495948791504,   acc:  0.6875\n",
      "Done with epoch 290 in 13.944495677947998s\n",
      "loss:   0.9093101024627686,   acc:  0.6875\n",
      "loss:   1.4010632038116455,   acc:  0.59375\n",
      "loss:   1.2968034744262695,   acc:  0.5625\n",
      "Done with epoch 291 in 21.01475429534912s\n",
      "loss:   1.196946144104004,   acc:  0.625\n",
      "loss:   0.9438126087188721,   acc:  0.75\n",
      "loss:   1.1721694469451904,   acc:  0.59375\n",
      "Done with epoch 292 in 19.971281051635742s\n",
      "loss:   1.3313539028167725,   acc:  0.53125\n",
      "loss:   0.8329930305480957,   acc:  0.6875\n",
      "loss:   0.9246141910552979,   acc:  0.65625\n",
      "Done with epoch 293 in 12.641640663146973s\n",
      "loss:   1.1924488544464111,   acc:  0.65625\n",
      "loss:   0.7116823196411133,   acc:  0.78125\n",
      "Done with epoch 294 in 12.72839069366455s\n",
      "loss:   1.4444403648376465,   acc:  0.5625\n",
      "loss:   1.157365083694458,   acc:  0.59375\n",
      "loss:   1.2314832210540771,   acc:  0.6875\n",
      "Done with epoch 295 in 12.610482931137085s\n",
      "loss:   1.247812271118164,   acc:  0.71875\n",
      "loss:   1.1603777408599854,   acc:  0.625\n",
      "loss:   0.9823534488677979,   acc:  0.65625\n",
      "Done with epoch 296 in 12.498950242996216s\n",
      "loss:   1.2672231197357178,   acc:  0.5625\n",
      "loss:   1.1422533988952637,   acc:  0.625\n",
      "loss:   1.5550782680511475,   acc:  0.40625\n",
      "Done with epoch 297 in 12.341826915740967s\n",
      "loss:   1.2044734954833984,   acc:  0.6875\n",
      "loss:   0.9599871635437012,   acc:  0.78125\n",
      "Saved model at ../models\\MPC_horizon_12_obs_10.pt\n",
      "loss:   1.314159631729126,   acc:  0.625\n",
      "Done with epoch 298 in 12.094664096832275s\n",
      "loss:   0.8932218551635742,   acc:  0.8125\n",
      "loss:   1.3244898319244385,   acc:  0.46875\n",
      "Done with epoch 299 in 11.375945568084717s\n",
      "loss:   0.9074404239654541,   acc:  0.75\n",
      "loss:   1.430178165435791,   acc:  0.5625\n",
      "loss:   0.9548590183258057,   acc:  0.75\n",
      "Done with epoch 300 in 11.679569482803345s\n",
      "loss:   1.1827483177185059,   acc:  0.625\n",
      "loss:   1.0837578773498535,   acc:  0.71875\n",
      "loss:   1.2021338939666748,   acc:  0.625\n",
      "Done with epoch 301 in 11.720287322998047s\n",
      "loss:   1.0591764450073242,   acc:  0.71875\n",
      "loss:   1.3637981414794922,   acc:  0.59375\n",
      "loss:   1.2162277698516846,   acc:  0.6875\n",
      "Done with epoch 302 in 11.364696979522705s\n",
      "loss:   1.3525903224945068,   acc:  0.5625\n",
      "loss:   1.8299744129180908,   acc:  0.53125\n",
      "loss:   1.2203474044799805,   acc:  0.5625\n",
      "Done with epoch 303 in 11.32914423942566s\n",
      "loss:   1.118356704711914,   acc:  0.65625\n",
      "loss:   1.286217212677002,   acc:  0.625\n",
      "Done with epoch 304 in 11.375872373580933s\n",
      "loss:   1.337545394897461,   acc:  0.59375\n",
      "loss:   1.1204886436462402,   acc:  0.65625\n",
      "loss:   1.3191978931427002,   acc:  0.59375\n",
      "Done with epoch 305 in 11.344788551330566s\n",
      "loss:   1.3582251071929932,   acc:  0.46875\n",
      "loss:   1.1600899696350098,   acc:  0.59375\n",
      "loss:   0.7042202949523926,   acc:  0.84375\n",
      "Done with epoch 306 in 11.704244613647461s\n",
      "loss:   1.5685982704162598,   acc:  0.5625\n",
      "loss:   0.9794204235076904,   acc:  0.65625\n",
      "loss:   1.7359113693237305,   acc:  0.5625\n",
      "Done with epoch 307 in 11.2937593460083s\n",
      "loss:   1.1150274276733398,   acc:  0.65625\n",
      "loss:   1.7045917510986328,   acc:  0.5625\n",
      "loss:   1.469822883605957,   acc:  0.5625\n",
      "Done with epoch 308 in 11.313767194747925s\n",
      "loss:   0.8897855281829834,   acc:  0.71875\n",
      "Saved model at ../models\\MPC_horizon_12_obs_10.pt\n",
      "loss:   1.0366265773773193,   acc:  0.59375\n",
      "loss:   1.1777513027191162,   acc:  0.625\n",
      "Done with epoch 309 in 11.375943660736084s\n",
      "loss:   0.9336378574371338,   acc:  0.71875\n",
      "loss:   1.2353768348693848,   acc:  0.65625\n",
      "Done with epoch 310 in 11.157451868057251s\n",
      "loss:   1.1215951442718506,   acc:  0.59375\n",
      "loss:   0.7168445587158203,   acc:  0.71875\n",
      "loss:   0.9100189208984375,   acc:  0.65625\n",
      "Done with epoch 311 in 11.329270839691162s\n",
      "loss:   1.364842176437378,   acc:  0.65625\n",
      "loss:   1.2758288383483887,   acc:  0.59375\n",
      "loss:   1.1102352142333984,   acc:  0.625\n",
      "Done with epoch 312 in 12.964793920516968s\n",
      "loss:   1.0518922805786133,   acc:  0.71875\n",
      "loss:   1.4019060134887695,   acc:  0.625\n",
      "loss:   1.132796287536621,   acc:  0.71875\n",
      "Done with epoch 313 in 11.375951528549194s\n",
      "loss:   1.1674189567565918,   acc:  0.5625\n",
      "loss:   0.7363166809082031,   acc:  0.75\n",
      "loss:   0.8124372959136963,   acc:  0.6875\n",
      "Done with epoch 314 in 11.344658613204956s\n",
      "loss:   0.7071568965911865,   acc:  0.8125\n",
      "loss:   1.0461649894714355,   acc:  0.625\n",
      "Done with epoch 315 in 11.204020261764526s\n",
      "loss:   1.2320313453674316,   acc:  0.59375\n",
      "loss:   1.4392049312591553,   acc:  0.5\n",
      "loss:   1.1814675331115723,   acc:  0.5625\n",
      "Done with epoch 316 in 11.329147100448608s\n",
      "loss:   1.2517919540405273,   acc:  0.71875\n",
      "loss:   1.1541016101837158,   acc:  0.625\n",
      "loss:   1.0783882141113281,   acc:  0.59375\n",
      "Done with epoch 317 in 12.558660507202148s\n",
      "loss:   1.0857610702514648,   acc:  0.6875\n",
      "loss:   0.9017524719238281,   acc:  0.75\n",
      "loss:   0.7743048667907715,   acc:  0.71875\n",
      "Done with epoch 318 in 11.579195499420166s\n",
      "loss:   0.9585087299346924,   acc:  0.65625\n",
      "loss:   1.3274457454681396,   acc:  0.53125\n",
      "loss:   0.9431257247924805,   acc:  0.6875\n",
      "Saved model at ../models\\MPC_horizon_12_obs_10.pt\n",
      "Done with epoch 319 in 11.32911992073059s\n",
      "loss:   0.9470071792602539,   acc:  0.6875\n",
      "loss:   1.4689979553222656,   acc:  0.5625\n",
      "Done with epoch 320 in 11.266513347625732s\n",
      "loss:   1.0850205421447754,   acc:  0.71875\n",
      "loss:   1.172778606414795,   acc:  0.59375\n",
      "loss:   1.1793663501739502,   acc:  0.65625\n",
      "Done with epoch 321 in 11.501062393188477s\n",
      "loss:   0.9603214263916016,   acc:  0.6875\n",
      "loss:   1.2381477355957031,   acc:  0.46875\n",
      "loss:   1.470820426940918,   acc:  0.5\n",
      "Done with epoch 322 in 11.388039588928223s\n",
      "loss:   0.6968069076538086,   acc:  0.8125\n",
      "loss:   1.2594070434570312,   acc:  0.625\n",
      "loss:   0.9513757228851318,   acc:  0.6875\n",
      "Done with epoch 323 in 11.610470294952393s\n",
      "loss:   1.087508201599121,   acc:  0.5625\n",
      "loss:   0.9043056964874268,   acc:  0.6875\n",
      "loss:   0.8757028579711914,   acc:  0.6875\n",
      "Done with epoch 324 in 11.375910758972168s\n",
      "loss:   1.613684892654419,   acc:  0.53125\n",
      "loss:   0.8892855644226074,   acc:  0.6875\n",
      "loss:   1.2730827331542969,   acc:  0.53125\n",
      "Done with epoch 325 in 18.150144815444946s\n",
      "loss:   1.5599005222320557,   acc:  0.5\n",
      "loss:   1.263742446899414,   acc:  0.625\n",
      "Done with epoch 326 in 20.399059772491455s\n",
      "loss:   1.2876038551330566,   acc:  0.53125\n",
      "loss:   1.1866350173950195,   acc:  0.65625\n",
      "loss:   0.8576791286468506,   acc:  0.75\n",
      "Done with epoch 327 in 21.500396013259888s\n",
      "loss:   1.5630898475646973,   acc:  0.625\n",
      "loss:   0.8699796199798584,   acc:  0.71875\n",
      "loss:   1.1839628219604492,   acc:  0.65625\n",
      "Done with epoch 328 in 20.843897819519043s\n",
      "loss:   1.5599510669708252,   acc:  0.4375\n",
      "loss:   1.0456068515777588,   acc:  0.59375\n",
      "loss:   1.169039249420166,   acc:  0.65625\n",
      "Done with epoch 329 in 21.86520481109619s\n",
      "loss:   0.8811612129211426,   acc:  0.84375\n",
      "loss:   0.7045447826385498,   acc:  0.78125\n",
      "Saved model at ../models\\MPC_horizon_12_obs_10.pt\n",
      "loss:   0.8643858432769775,   acc:  0.65625\n",
      "Done with epoch 330 in 21.48376202583313s\n",
      "loss:   0.7880392074584961,   acc:  0.65625\n",
      "loss:   1.516477346420288,   acc:  0.5625\n",
      "Done with epoch 331 in 20.936997175216675s\n",
      "loss:   1.5555775165557861,   acc:  0.59375\n",
      "loss:   1.2853584289550781,   acc:  0.53125\n",
      "loss:   1.4298570156097412,   acc:  0.65625\n",
      "Done with epoch 332 in 21.950660467147827s\n",
      "loss:   1.1885490417480469,   acc:  0.625\n",
      "loss:   0.7430553436279297,   acc:  0.71875\n",
      "loss:   0.9399209022521973,   acc:  0.6875\n",
      "Done with epoch 333 in 28.150536060333252s\n",
      "loss:   0.9321858882904053,   acc:  0.75\n",
      "loss:   1.228811502456665,   acc:  0.71875\n",
      "loss:   1.2739737033843994,   acc:  0.59375\n",
      "Done with epoch 334 in 24.41098141670227s\n",
      "loss:   0.9319643974304199,   acc:  0.6875\n",
      "loss:   0.8420186042785645,   acc:  0.75\n",
      "loss:   1.3284995555877686,   acc:  0.5625\n",
      "Done with epoch 335 in 24.39018487930298s\n",
      "loss:   1.249593734741211,   acc:  0.5625\n",
      "loss:   1.0093133449554443,   acc:  0.625\n",
      "Done with epoch 336 in 24.290008306503296s\n",
      "loss:   1.3199357986450195,   acc:  0.5625\n",
      "loss:   1.2429547309875488,   acc:  0.5625\n",
      "loss:   0.9752283096313477,   acc:  0.6875\n",
      "Done with epoch 337 in 24.464171171188354s\n",
      "loss:   0.7482373714447021,   acc:  0.78125\n",
      "loss:   1.5193188190460205,   acc:  0.6875\n",
      "loss:   1.085662603378296,   acc:  0.625\n",
      "Done with epoch 338 in 24.466843366622925s\n",
      "loss:   0.9966857433319092,   acc:  0.71875\n",
      "loss:   0.8694577217102051,   acc:  0.78125\n",
      "loss:   1.6672554016113281,   acc:  0.5\n",
      "Done with epoch 339 in 25.610337257385254s\n",
      "loss:   0.7896227836608887,   acc:  0.78125\n",
      "loss:   0.7979385852813721,   acc:  0.78125\n",
      "loss:   1.4715759754180908,   acc:  0.46875\n",
      "Done with epoch 340 in 24.276010990142822s\n",
      "loss:   1.006089210510254,   acc:  0.6875\n",
      "Saved model at ../models\\MPC_horizon_12_obs_10.pt\n",
      "loss:   1.292625904083252,   acc:  0.625\n",
      "loss:   0.8372960090637207,   acc:  0.75\n",
      "Done with epoch 341 in 24.195008039474487s\n",
      "loss:   0.6492118835449219,   acc:  0.78125\n",
      "loss:   1.0285542011260986,   acc:  0.6875\n",
      "Done with epoch 342 in 23.87699294090271s\n",
      "loss:   1.1180272102355957,   acc:  0.625\n",
      "loss:   0.9143555164337158,   acc:  0.65625\n",
      "loss:   1.0076866149902344,   acc:  0.75\n",
      "Done with epoch 343 in 24.769073724746704s\n",
      "loss:   1.1593718528747559,   acc:  0.625\n",
      "loss:   1.0730462074279785,   acc:  0.625\n",
      "loss:   1.169435977935791,   acc:  0.75\n",
      "Done with epoch 344 in 24.945000648498535s\n",
      "loss:   1.14082670211792,   acc:  0.75\n",
      "loss:   1.2175207138061523,   acc:  0.65625\n",
      "loss:   0.7680096626281738,   acc:  0.75\n",
      "Done with epoch 345 in 24.86503529548645s\n",
      "loss:   1.3064279556274414,   acc:  0.59375\n",
      "loss:   1.1446542739868164,   acc:  0.71875\n",
      "loss:   1.341008186340332,   acc:  0.625\n",
      "Done with epoch 346 in 24.979002475738525s\n",
      "loss:   0.9482650756835938,   acc:  0.71875\n",
      "loss:   0.9069371223449707,   acc:  0.71875\n",
      "Done with epoch 347 in 24.661005973815918s\n",
      "loss:   1.172008991241455,   acc:  0.65625\n",
      "loss:   1.3634326457977295,   acc:  0.5\n",
      "loss:   1.0693531036376953,   acc:  0.5625\n",
      "Done with epoch 348 in 25.10999321937561s\n",
      "loss:   1.2558705806732178,   acc:  0.59375\n",
      "loss:   1.221653938293457,   acc:  0.625\n",
      "loss:   0.9090306758880615,   acc:  0.625\n",
      "Done with epoch 349 in 25.291004180908203s\n",
      "loss:   1.5755903720855713,   acc:  0.625\n",
      "loss:   1.1770198345184326,   acc:  0.625\n",
      "loss:   1.1461539268493652,   acc:  0.71875\n",
      "Done with epoch 350 in 25.430996656417847s\n",
      "loss:   1.048734426498413,   acc:  0.71875\n",
      "loss:   0.6560473442077637,   acc:  0.78125\n",
      "loss:   1.2606806755065918,   acc:  0.65625\n",
      "Saved model at ../models\\MPC_horizon_12_obs_10.pt\n",
      "Done with epoch 351 in 24.944018125534058s\n",
      "loss:   0.8716428279876709,   acc:  0.78125\n",
      "loss:   1.1340250968933105,   acc:  0.65625\n",
      "Done with epoch 352 in 24.529035091400146s\n",
      "loss:   1.6101293563842773,   acc:  0.5625\n",
      "loss:   1.3980374336242676,   acc:  0.625\n",
      "loss:   0.9488909244537354,   acc:  0.75\n",
      "Done with epoch 353 in 22.703327894210815s\n",
      "loss:   1.0462746620178223,   acc:  0.65625\n",
      "loss:   1.1356201171875,   acc:  0.59375\n",
      "loss:   1.4496657848358154,   acc:  0.53125\n",
      "Done with epoch 354 in 24.010996341705322s\n",
      "loss:   1.0393447875976562,   acc:  0.5625\n",
      "loss:   1.4047024250030518,   acc:  0.5\n",
      "loss:   1.2686758041381836,   acc:  0.71875\n",
      "Done with epoch 355 in 23.613734006881714s\n",
      "loss:   1.1270861625671387,   acc:  0.71875\n",
      "loss:   0.9062528610229492,   acc:  0.8125\n",
      "loss:   0.6812548637390137,   acc:  0.78125\n",
      "Done with epoch 356 in 24.291998386383057s\n",
      "loss:   1.0658354759216309,   acc:  0.65625\n",
      "loss:   0.9714550971984863,   acc:  0.6875\n",
      "loss:   1.1208980083465576,   acc:  0.71875\n",
      "Done with epoch 357 in 25.34399962425232s\n",
      "loss:   1.4707040786743164,   acc:  0.625\n",
      "loss:   0.9515790939331055,   acc:  0.75\n",
      "Done with epoch 358 in 25.57700252532959s\n",
      "loss:   1.2433338165283203,   acc:  0.5625\n",
      "loss:   1.101323127746582,   acc:  0.65625\n",
      "loss:   1.0884294509887695,   acc:  0.71875\n",
      "Done with epoch 359 in 25.399005651474s\n",
      "loss:   0.6330580711364746,   acc:  0.75\n",
      "loss:   1.388075828552246,   acc:  0.5625\n",
      "loss:   0.9998915195465088,   acc:  0.59375\n",
      "Done with epoch 360 in 25.321999549865723s\n",
      "loss:   1.274261236190796,   acc:  0.625\n",
      "loss:   0.8519554138183594,   acc:  0.75\n",
      "loss:   1.0961401462554932,   acc:  0.65625\n",
      "Done with epoch 361 in 23.283026456832886s\n",
      "loss:   1.1021347045898438,   acc:  0.6875\n",
      "loss:   0.959968090057373,   acc:  0.65625\n",
      "Saved model at ../models\\MPC_horizon_12_obs_10.pt\n",
      "loss:   0.8411741256713867,   acc:  0.6875\n",
      "Done with epoch 362 in 23.132967472076416s\n",
      "loss:   1.5598559379577637,   acc:  0.46875\n",
      "loss:   0.8973128795623779,   acc:  0.71875\n",
      "Done with epoch 363 in 23.365215301513672s\n",
      "loss:   1.45924973487854,   acc:  0.53125\n",
      "loss:   1.3940343856811523,   acc:  0.625\n",
      "loss:   1.2390823364257812,   acc:  0.5625\n",
      "Done with epoch 364 in 22.400094509124756s\n",
      "loss:   0.6966395378112793,   acc:  0.875\n",
      "loss:   0.6769745349884033,   acc:  0.71875\n",
      "loss:   1.148005485534668,   acc:  0.59375\n",
      "Done with epoch 365 in 22.01259183883667s\n",
      "loss:   1.1771531105041504,   acc:  0.71875\n",
      "loss:   0.8694798946380615,   acc:  0.6875\n",
      "loss:   1.3546326160430908,   acc:  0.5625\n",
      "Done with epoch 366 in 22.27949547767639s\n",
      "loss:   1.3019542694091797,   acc:  0.4375\n",
      "loss:   0.7447314262390137,   acc:  0.84375\n",
      "loss:   0.9723021984100342,   acc:  0.6875\n",
      "Done with epoch 367 in 23.1440007686615s\n",
      "loss:   1.6089849472045898,   acc:  0.59375\n",
      "loss:   0.8195216655731201,   acc:  0.71875\n",
      "Done with epoch 368 in 22.286996603012085s\n",
      "loss:   1.4814643859863281,   acc:  0.46875\n",
      "loss:   1.3105220794677734,   acc:  0.625\n",
      "loss:   1.4201445579528809,   acc:  0.5625\n",
      "Done with epoch 369 in 22.82399606704712s\n",
      "loss:   0.9998176097869873,   acc:  0.71875\n",
      "loss:   0.8585383892059326,   acc:  0.6875\n",
      "loss:   0.8645675182342529,   acc:  0.71875\n",
      "Done with epoch 370 in 23.523000955581665s\n",
      "loss:   1.6141586303710938,   acc:  0.5625\n",
      "loss:   1.3536128997802734,   acc:  0.5625\n",
      "loss:   0.6052913665771484,   acc:  0.84375\n",
      "Done with epoch 371 in 24.074050664901733s\n",
      "loss:   0.9567975997924805,   acc:  0.65625\n",
      "loss:   1.2681818008422852,   acc:  0.46875\n",
      "loss:   0.8360798358917236,   acc:  0.71875\n",
      "Done with epoch 372 in 23.919996738433838s\n",
      "loss:   1.427868366241455,   acc:  0.6875\n",
      "Saved model at ../models\\MPC_horizon_12_obs_10.pt\n",
      "loss:   1.0164289474487305,   acc:  0.6875\n",
      "loss:   1.1414799690246582,   acc:  0.5625\n",
      "Done with epoch 373 in 23.340018272399902s\n",
      "loss:   0.9672715663909912,   acc:  0.625\n",
      "loss:   1.4509243965148926,   acc:  0.625\n",
      "Done with epoch 374 in 23.7549786567688s\n",
      "loss:   1.2211594581604004,   acc:  0.625\n",
      "loss:   1.0029921531677246,   acc:  0.6875\n",
      "loss:   1.321589469909668,   acc:  0.65625\n",
      "Done with epoch 375 in 23.243003129959106s\n",
      "loss:   0.9232869148254395,   acc:  0.75\n",
      "loss:   1.1927094459533691,   acc:  0.65625\n",
      "loss:   0.805595874786377,   acc:  0.625\n",
      "Done with epoch 376 in 22.791014194488525s\n",
      "loss:   1.0555329322814941,   acc:  0.59375\n",
      "loss:   1.004636287689209,   acc:  0.6875\n",
      "loss:   0.9869155883789062,   acc:  0.78125\n",
      "Done with epoch 377 in 22.266478061676025s\n",
      "loss:   0.9683289527893066,   acc:  0.71875\n",
      "loss:   0.993349552154541,   acc:  0.6875\n",
      "loss:   1.282973289489746,   acc:  0.65625\n",
      "Done with epoch 378 in 21.540008783340454s\n",
      "loss:   1.0873017311096191,   acc:  0.59375\n",
      "loss:   0.9166638851165771,   acc:  0.6875\n",
      "Done with epoch 379 in 22.979999542236328s\n",
      "loss:   0.7992129325866699,   acc:  0.75\n",
      "loss:   0.817535400390625,   acc:  0.75\n",
      "loss:   0.8007609844207764,   acc:  0.75\n",
      "Done with epoch 380 in 22.117194175720215s\n",
      "loss:   1.0252056121826172,   acc:  0.65625\n",
      "loss:   1.3145873546600342,   acc:  0.625\n",
      "loss:   1.745497226715088,   acc:  0.53125\n",
      "Done with epoch 381 in 22.71702480316162s\n",
      "loss:   1.256197452545166,   acc:  0.625\n",
      "loss:   1.2681965827941895,   acc:  0.625\n",
      "loss:   1.2048006057739258,   acc:  0.625\n",
      "Done with epoch 382 in 25.651767253875732s\n",
      "loss:   0.7474660873413086,   acc:  0.65625\n",
      "loss:   0.748706579208374,   acc:  0.75\n",
      "loss:   0.7886066436767578,   acc:  0.71875\n",
      "Saved model at ../models\\MPC_horizon_12_obs_10.pt\n",
      "Done with epoch 383 in 23.369009017944336s\n",
      "loss:   1.6867990493774414,   acc:  0.53125\n",
      "loss:   0.8458518981933594,   acc:  0.84375\n",
      "loss:   1.4520115852355957,   acc:  0.6875\n",
      "Done with epoch 384 in 23.02238416671753s\n",
      "loss:   1.2886910438537598,   acc:  0.53125\n",
      "loss:   1.084423303604126,   acc:  0.65625\n",
      "Done with epoch 385 in 23.26002860069275s\n",
      "loss:   0.9368381500244141,   acc:  0.75\n",
      "loss:   0.8868956565856934,   acc:  0.75\n",
      "loss:   1.3047823905944824,   acc:  0.65625\n",
      "Done with epoch 386 in 22.067047595977783s\n",
      "loss:   0.897402286529541,   acc:  0.71875\n",
      "loss:   1.1005172729492188,   acc:  0.65625\n",
      "loss:   1.1604375839233398,   acc:  0.59375\n",
      "Done with epoch 387 in 24.18790578842163s\n",
      "loss:   0.7994735240936279,   acc:  0.78125\n",
      "loss:   1.059647560119629,   acc:  0.71875\n",
      "loss:   1.0736069679260254,   acc:  0.65625\n",
      "Done with epoch 388 in 24.950001001358032s\n",
      "loss:   0.9663076400756836,   acc:  0.6875\n",
      "loss:   1.0637977123260498,   acc:  0.65625\n",
      "loss:   1.2657601833343506,   acc:  0.53125\n",
      "Done with epoch 389 in 23.683000326156616s\n",
      "loss:   1.0794706344604492,   acc:  0.59375\n",
      "loss:   0.8526406288146973,   acc:  0.75\n",
      "Done with epoch 390 in 23.86702060699463s\n",
      "loss:   1.0143096446990967,   acc:  0.75\n",
      "loss:   1.3538575172424316,   acc:  0.5\n",
      "loss:   0.6590657234191895,   acc:  0.71875\n",
      "Done with epoch 391 in 25.132988214492798s\n",
      "loss:   1.1740169525146484,   acc:  0.65625\n",
      "loss:   1.5047264099121094,   acc:  0.59375\n",
      "loss:   1.1688165664672852,   acc:  0.59375\n",
      "Done with epoch 392 in 25.0180242061615s\n",
      "loss:   0.8682479858398438,   acc:  0.6875\n",
      "loss:   0.7340126037597656,   acc:  0.6875\n",
      "loss:   0.6384518146514893,   acc:  0.8125\n",
      "Done with epoch 393 in 25.21399974822998s\n",
      "loss:   0.906574010848999,   acc:  0.78125\n",
      "loss:   0.8472161293029785,   acc:  0.75\n",
      "Saved model at ../models\\MPC_horizon_12_obs_10.pt\n",
      "loss:   1.088794231414795,   acc:  0.6875\n",
      "Done with epoch 394 in 24.54453444480896s\n",
      "loss:   1.3804292678833008,   acc:  0.5625\n",
      "loss:   1.0021491050720215,   acc:  0.6875\n",
      "Done with epoch 395 in 24.357999086380005s\n",
      "loss:   0.9877967834472656,   acc:  0.6875\n",
      "loss:   1.0476605892181396,   acc:  0.5625\n",
      "loss:   1.2268924713134766,   acc:  0.625\n",
      "Done with epoch 396 in 25.55100107192993s\n",
      "loss:   0.9100539684295654,   acc:  0.71875\n",
      "loss:   1.1776728630065918,   acc:  0.65625\n",
      "loss:   1.042090654373169,   acc:  0.71875\n",
      "Done with epoch 397 in 26.148001194000244s\n",
      "loss:   0.9928936958312988,   acc:  0.71875\n",
      "loss:   1.2545249462127686,   acc:  0.6875\n",
      "loss:   1.0794308185577393,   acc:  0.65625\n",
      "Done with epoch 398 in 22.775645971298218s\n",
      "loss:   0.7445464134216309,   acc:  0.71875\n",
      "loss:   1.1003081798553467,   acc:  0.6875\n",
      "loss:   1.1581709384918213,   acc:  0.65625\n",
      "Done with epoch 399 in 22.631962299346924s\n",
      "loss:   1.2031464576721191,   acc:  0.59375\n",
      "loss:   0.87972092628479,   acc:  0.6875\n",
      "loss:   1.1106886863708496,   acc:  0.65625\n",
      "Done with epoch 400 in 24.02299952507019s\n",
      "loss:   1.5209875106811523,   acc:  0.5625\n",
      "loss:   1.1414809226989746,   acc:  0.625\n",
      "Done with epoch 401 in 24.92799711227417s\n",
      "loss:   1.4046015739440918,   acc:  0.53125\n",
      "loss:   0.8520684242248535,   acc:  0.78125\n",
      "loss:   1.3264706134796143,   acc:  0.65625\n",
      "Done with epoch 402 in 26.077040433883667s\n",
      "loss:   0.8861074447631836,   acc:  0.65625\n",
      "loss:   0.6760745048522949,   acc:  0.78125\n",
      "loss:   1.3815326690673828,   acc:  0.625\n",
      "Done with epoch 403 in 25.85797429084778s\n",
      "loss:   0.9898920059204102,   acc:  0.71875\n",
      "loss:   1.4050071239471436,   acc:  0.625\n",
      "loss:   1.1951379776000977,   acc:  0.59375\n",
      "Done with epoch 404 in 26.400995016098022s\n",
      "loss:   0.9706180095672607,   acc:  0.65625\n",
      "Saved model at ../models\\MPC_horizon_12_obs_10.pt\n",
      "loss:   1.121079444885254,   acc:  0.59375\n",
      "loss:   0.9029722213745117,   acc:  0.65625\n",
      "Done with epoch 405 in 25.239003896713257s\n",
      "loss:   1.758638858795166,   acc:  0.5\n",
      "loss:   0.7591524124145508,   acc:  0.71875\n",
      "Done with epoch 406 in 23.830008506774902s\n",
      "loss:   1.2072515487670898,   acc:  0.75\n",
      "loss:   1.305891990661621,   acc:  0.59375\n",
      "loss:   1.148205280303955,   acc:  0.65625\n",
      "Done with epoch 407 in 24.39877486228943s\n",
      "loss:   0.967686653137207,   acc:  0.625\n",
      "loss:   1.3964879512786865,   acc:  0.5625\n",
      "loss:   0.7849898338317871,   acc:  0.6875\n",
      "Done with epoch 408 in 25.14202570915222s\n",
      "loss:   1.4566230773925781,   acc:  0.5\n",
      "loss:   1.3746967315673828,   acc:  0.625\n",
      "loss:   1.6934638023376465,   acc:  0.5\n",
      "Done with epoch 409 in 25.25502061843872s\n",
      "loss:   1.4628674983978271,   acc:  0.65625\n",
      "loss:   0.8844046592712402,   acc:  0.65625\n",
      "loss:   1.2157268524169922,   acc:  0.59375\n",
      "Done with epoch 410 in 25.116018056869507s\n",
      "loss:   1.150543451309204,   acc:  0.59375\n",
      "loss:   1.217440128326416,   acc:  0.6875\n",
      "Done with epoch 411 in 20.698150634765625s\n",
      "loss:   1.1466760635375977,   acc:  0.65625\n",
      "loss:   1.2890491485595703,   acc:  0.625\n",
      "loss:   1.1488447189331055,   acc:  0.59375\n",
      "Done with epoch 412 in 20.918241262435913s\n",
      "loss:   1.222670078277588,   acc:  0.625\n",
      "loss:   1.381558895111084,   acc:  0.59375\n",
      "loss:   1.0351672172546387,   acc:  0.6875\n",
      "Done with epoch 413 in 20.560282230377197s\n",
      "loss:   1.2673449516296387,   acc:  0.65625\n",
      "loss:   0.9277243614196777,   acc:  0.75\n",
      "loss:   1.125525712966919,   acc:  0.71875\n",
      "Done with epoch 414 in 20.69243812561035s\n",
      "loss:   0.9913556575775146,   acc:  0.75\n",
      "loss:   0.7476377487182617,   acc:  0.75\n",
      "loss:   1.1100177764892578,   acc:  0.65625\n",
      "Saved model at ../models\\MPC_horizon_12_obs_10.pt\n",
      "Done with epoch 415 in 20.89688777923584s\n",
      "loss:   0.9917745590209961,   acc:  0.65625\n",
      "loss:   0.9096493721008301,   acc:  0.75\n",
      "loss:   0.7975707054138184,   acc:  0.75\n",
      "Done with epoch 416 in 20.901084184646606s\n",
      "loss:   1.2208247184753418,   acc:  0.59375\n",
      "loss:   0.8909568786621094,   acc:  0.71875\n",
      "Done with epoch 417 in 20.764436960220337s\n",
      "loss:   1.2830536365509033,   acc:  0.6875\n",
      "loss:   1.0920162200927734,   acc:  0.65625\n",
      "loss:   0.7729272842407227,   acc:  0.78125\n",
      "Done with epoch 418 in 20.667156457901s\n",
      "loss:   1.2585570812225342,   acc:  0.6875\n",
      "loss:   1.052844524383545,   acc:  0.71875\n",
      "loss:   1.0409860610961914,   acc:  0.71875\n",
      "Done with epoch 419 in 21.034327030181885s\n",
      "loss:   0.9263677597045898,   acc:  0.71875\n",
      "loss:   1.3069050312042236,   acc:  0.53125\n",
      "loss:   0.8034298419952393,   acc:  0.6875\n",
      "Done with epoch 420 in 20.685683965682983s\n",
      "loss:   1.2391667366027832,   acc:  0.6875\n",
      "loss:   0.8608388900756836,   acc:  0.78125\n",
      "loss:   1.166715145111084,   acc:  0.65625\n",
      "Done with epoch 421 in 20.846808195114136s\n",
      "loss:   1.178360939025879,   acc:  0.53125\n",
      "loss:   0.976144552230835,   acc:  0.71875\n",
      "Done with epoch 422 in 20.86148452758789s\n",
      "loss:   0.8489768505096436,   acc:  0.71875\n",
      "loss:   1.204625129699707,   acc:  0.53125\n",
      "loss:   1.485083818435669,   acc:  0.5\n",
      "Done with epoch 423 in 20.571717500686646s\n",
      "loss:   1.3969159126281738,   acc:  0.625\n",
      "loss:   1.327756404876709,   acc:  0.5625\n",
      "loss:   1.5474951267242432,   acc:  0.53125\n",
      "Done with epoch 424 in 21.158250093460083s\n",
      "loss:   0.9906177520751953,   acc:  0.65625\n",
      "loss:   0.7344322204589844,   acc:  0.8125\n",
      "loss:   1.2345192432403564,   acc:  0.625\n",
      "Done with epoch 425 in 21.032807111740112s\n",
      "loss:   1.049849510192871,   acc:  0.6875\n",
      "loss:   1.3376491069793701,   acc:  0.625\n",
      "Saved model at ../models\\MPC_horizon_12_obs_10.pt\n",
      "loss:   0.9690732955932617,   acc:  0.75\n",
      "Done with epoch 426 in 20.83342695236206s\n",
      "loss:   1.2799673080444336,   acc:  0.6875\n",
      "loss:   0.662773609161377,   acc:  0.8125\n",
      "Done with epoch 427 in 20.545421838760376s\n",
      "loss:   1.1681289672851562,   acc:  0.65625\n",
      "loss:   1.1957778930664062,   acc:  0.71875\n",
      "loss:   1.096877098083496,   acc:  0.53125\n",
      "Done with epoch 428 in 21.16907048225403s\n",
      "loss:   0.9878768920898438,   acc:  0.71875\n",
      "loss:   1.1182587146759033,   acc:  0.65625\n",
      "loss:   1.113668441772461,   acc:  0.65625\n",
      "Done with epoch 429 in 20.80436134338379s\n",
      "loss:   1.321180820465088,   acc:  0.625\n",
      "loss:   1.310802936553955,   acc:  0.59375\n",
      "loss:   0.7885980606079102,   acc:  0.71875\n",
      "Done with epoch 430 in 20.755382299423218s\n",
      "loss:   0.7928705215454102,   acc:  0.75\n",
      "loss:   0.8221206665039062,   acc:  0.6875\n",
      "loss:   1.2268013954162598,   acc:  0.6875\n",
      "Done with epoch 431 in 21.098830699920654s\n",
      "loss:   1.2123346328735352,   acc:  0.65625\n",
      "loss:   0.8780364990234375,   acc:  0.8125\n",
      "loss:   1.1381950378417969,   acc:  0.71875\n",
      "Done with epoch 432 in 20.60433292388916s\n",
      "loss:   1.1447923183441162,   acc:  0.625\n",
      "loss:   0.7019104957580566,   acc:  0.75\n",
      "Done with epoch 433 in 21.720096111297607s\n",
      "loss:   0.8977046012878418,   acc:  0.75\n",
      "loss:   1.6202330589294434,   acc:  0.53125\n",
      "loss:   0.8513050079345703,   acc:  0.6875\n",
      "Done with epoch 434 in 23.45726227760315s\n",
      "loss:   1.0451440811157227,   acc:  0.65625\n",
      "loss:   1.1247234344482422,   acc:  0.6875\n",
      "loss:   0.7326416969299316,   acc:  0.71875\n",
      "Done with epoch 435 in 24.087982177734375s\n",
      "loss:   1.3679327964782715,   acc:  0.53125\n",
      "loss:   1.275324821472168,   acc:  0.5625\n",
      "loss:   0.8991518020629883,   acc:  0.65625\n",
      "Done with epoch 436 in 25.037013053894043s\n",
      "loss:   1.408414602279663,   acc:  0.5625\n",
      "Saved model at ../models\\MPC_horizon_12_obs_10.pt\n",
      "loss:   0.921630859375,   acc:  0.78125\n",
      "loss:   1.222120761871338,   acc:  0.5\n",
      "Done with epoch 437 in 25.525931358337402s\n",
      "loss:   1.0015017986297607,   acc:  0.59375\n",
      "loss:   0.8090014457702637,   acc:  0.78125\n",
      "Done with epoch 438 in 23.91201615333557s\n",
      "loss:   0.8715906143188477,   acc:  0.6875\n",
      "loss:   1.2659187316894531,   acc:  0.5625\n",
      "loss:   0.8458127975463867,   acc:  0.6875\n",
      "Done with epoch 439 in 25.131185054779053s\n",
      "loss:   1.412175178527832,   acc:  0.5625\n",
      "loss:   1.1476266384124756,   acc:  0.65625\n",
      "loss:   1.2943344116210938,   acc:  0.78125\n",
      "Done with epoch 440 in 25.076012134552002s\n",
      "loss:   0.9009876251220703,   acc:  0.71875\n",
      "loss:   1.241633415222168,   acc:  0.53125\n",
      "loss:   1.1081469058990479,   acc:  0.65625\n",
      "Done with epoch 441 in 25.111997604370117s\n",
      "loss:   0.9421029090881348,   acc:  0.71875\n",
      "loss:   1.5175971984863281,   acc:  0.6875\n",
      "loss:   1.2585086822509766,   acc:  0.6875\n",
      "Done with epoch 442 in 25.07099175453186s\n",
      "loss:   1.240511417388916,   acc:  0.59375\n",
      "loss:   0.5568132400512695,   acc:  0.84375\n",
      "Done with epoch 443 in 25.318002223968506s\n",
      "loss:   1.051788568496704,   acc:  0.65625\n",
      "loss:   0.9843430519104004,   acc:  0.75\n",
      "loss:   1.3155956268310547,   acc:  0.6875\n",
      "Done with epoch 444 in 24.754032373428345s\n",
      "loss:   1.392676830291748,   acc:  0.625\n",
      "loss:   1.2330799102783203,   acc:  0.59375\n",
      "loss:   1.207491397857666,   acc:  0.625\n",
      "Done with epoch 445 in 25.052999258041382s\n",
      "loss:   0.8463420867919922,   acc:  0.71875\n",
      "loss:   1.0336251258850098,   acc:  0.65625\n",
      "loss:   0.8330457210540771,   acc:  0.71875\n",
      "Done with epoch 446 in 24.523175477981567s\n",
      "loss:   1.096238613128662,   acc:  0.6875\n",
      "loss:   0.8646023273468018,   acc:  0.75\n",
      "loss:   0.8572201728820801,   acc:  0.75\n",
      "Saved model at ../models\\MPC_horizon_12_obs_10.pt\n",
      "Done with epoch 447 in 24.05165147781372s\n",
      "loss:   1.050194263458252,   acc:  0.625\n",
      "loss:   1.482393741607666,   acc:  0.53125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-8-c20e3be8ed5f>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mMPC_obj\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtraining_params\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'TRAINING_ITERATIONS'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m500\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mMPC_obj\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_data\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtrain_data\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[0mMPC_obj\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Curious\\OMISTL\\solvers\\OMISTL.py\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(self, train_data, verbose)\u001B[0m\n\u001B[0;32m    353\u001B[0m                 \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    354\u001B[0m                 \u001B[1;31m#torch.nn.utils.clip_grad_norm(model.parameters(),0.1)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 355\u001B[1;33m                 \u001B[0mopt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    356\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    357\u001B[0m                 \u001B[1;31m# print statistics\\n\",\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\coco\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001B[0m in \u001B[0;36mdecorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     13\u001B[0m         \u001B[1;32mdef\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 15\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     16\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\coco\\lib\\site-packages\\torch\\optim\\adam.py\u001B[0m in \u001B[0;36mstep\u001B[1;34m(self, closure)\u001B[0m\n\u001B[0;32m     94\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     95\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mgroup\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'weight_decay'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 96\u001B[1;33m                     \u001B[0mgrad\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgrad\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mp\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0malpha\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mgroup\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'weight_decay'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     97\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     98\u001B[0m                 \u001B[1;31m# Decay the first and second moment running average coefficient\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# MPC_obj.training_params['TRAINING_ITERATIONS'] = 500\n",
    "# MPC_obj.train(train_data=train_data, verbose=True)\n",
    "# MPC_obj.model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found solution! n_evals = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msi\\anaconda3\\envs\\coco\\lib\\site-packages\\cvxpy\\problems\\problem.py:1306: UserWarning: \n",
      "    The problem is either infeasible or unbounded, but the solver\n",
      "    cannot tell which. Disable any solver-specific presolve methods\n",
      "    and re-solve to determine the precise problem status.\n",
      "\n",
      "    For GUROBI and CPLEX you can automatically perform this re-solve\n",
      "    with the keyword argument prob.solve(reoptimize=True, ...).\n",
      "    \n",
      "  warnings.warn(INF_OR_UNB_MESSAGE)\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.015625"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outfile = open(config_fn,\"rb\")\n",
    "config=pickle.load(outfile)\n",
    "velmin = -0.2\n",
    "velmax = 0.2\n",
    "posmin = np.zeros(2)\n",
    "n_obs = config[1][5]\n",
    "\n",
    "ft2m = 0.3048\n",
    "posmax = ft2m*np.array([12.,9.])\n",
    "max_box_size = 0.75\n",
    "min_box_size = 0.25\n",
    "box_buffer = 0.025\n",
    "border_size = 0.05\n",
    "\n",
    "obstacles = config[-1]\n",
    "\n",
    "\n",
    "# x0 = findIC(obstacles, posmin=posmin, posmax=posmax, velmin=velmin, velmax=velmax)\n",
    "# xg = findIC(obstacles, posmin=posmin, posmax=posmax, velmin=velmin, velmax=velmax)\n",
    "x0 = [0.1,0.1,0,0]\n",
    "xg = [3,0.5,0,0]\n",
    "\n",
    "# obstacles = \\\n",
    "#         random_obs(n_obs, posmin, posmax, border_size, box_buffer, min_box_size, max_box_size)\n",
    "obstacles= config[-1]\n",
    "\n",
    "prob_success = False\n",
    "while not prob_success:\n",
    "    prob_params = {}\n",
    "    idx = np.random.randint(test_data[1].shape[0])\n",
    "    for k in p_test.keys():\n",
    "        prob_params[k] = p_test[k][idx]\n",
    "    # prob_params['obstacles'] =  np.reshape(np.concatenate(obstacles, axis=0), (n_obs,4)).T\n",
    "    # prob_params['x0'] = x0\n",
    "    # prob_params['xg'] = xg\n",
    "\n",
    "    prob_success, cost, total_time, n_evals, optvals,y_guess = MPC_obj.forward(prob_params, solver=cp.GUROBI, max_evals=10)\n",
    "    # prob_success, cost, total_time, n_evals, optvals = coco_obj.forward(p_dict, solver=cp.GUROBI, max_evals=10)\n",
    "    if prob_success:\n",
    "        print('Found solution! ' + \"n_evals = \" + str(n_evals))\n",
    "    else:\n",
    "        print('Failed')\n",
    "total_time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Xopt = optvals[0]\n",
    "#\n",
    "# obstacles = []\n",
    "# for ii_obs in range(n_obs):\n",
    "#     obs = prob_params['obstacles'][:,ii_obs]\n",
    "#     obstacles.append(obs)\n",
    "#\n",
    "# if len(obstacles) is n_obs:\n",
    "#     plt.axes()\n",
    "#     for obstacle in obstacles:\n",
    "#         rectangle = plt.Rectangle((obstacle[0], obstacle[2]), \\\n",
    "#                                   obstacle[1]-obstacle[0], obstacle[3]-obstacle[2], \\\n",
    "#                                  fc='white', ec='black')\n",
    "#         plt.gca().add_patch(rectangle)\n",
    "#         plt.axis('scaled')\n",
    "#\n",
    "#\n",
    "#     xg = prob_params['xg']\n",
    "#     x0 = prob_params['x0']\n",
    "#     circle = plt.Circle((x0[0],x0[1]), 0.04, fc='blue',ec=\"blue\")\n",
    "#     plt.gca().add_patch(circle)\n",
    "#\n",
    "#     #blue line is network prediction\n",
    "#     plt.plot(xg[0],xg[1],'sr')\n",
    "#     # plt.quiver(Xopt[0,:], Xopt[1,:], Xopt[2,:], Xopt[3,:])#plot using arrows\n",
    "#     for jj in range(N):\n",
    "#         circle = plt.Circle((Xopt[0,jj],Xopt[1,jj]), 0.02, fc='red',ec=\"red\")\n",
    "#         plt.gca().add_patch(circle)\n",
    "#\n",
    "#\n",
    "#     ax = plt.gca()\n",
    "#     ax.margins(0)\n",
    "#     ax.set(xlim=(posmin[0],posmax[0]), ylim=(posmin[1],posmax[1]))\n",
    "#     plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_test = 2000\n",
    "framework = 'OMISTL'\n",
    "n_succ = 0\n",
    "count = 0\n",
    "gurobi_fail = 0\n",
    "\n",
    "costs = []\n",
    "total_time_ML = []\n",
    "num_solves = []\n",
    "\n",
    "cost_ratios = []\n",
    "costs_ip = []\n",
    "total_time_ip = []\n",
    "\n",
    "for ii in tqdm(range(n_test)):\n",
    "    if ii % 1000 == 0:\n",
    "        print('{} / {}'.format(ii,n_test))\n",
    "    prob_params = {}\n",
    "    for k in p_test.keys():\n",
    "        prob_params[k] = p_test[k][ii]\n",
    "\n",
    "    try:\n",
    "        prob_success, cost, total_time, n_evals, optvals,y_guess = MPC_obj.forward(prob_params, max_evals=10, solver=cp.GUROBI)\n",
    "\n",
    "        if prob_success:\n",
    "            n_succ += 1\n",
    "            costs += [cost]\n",
    "            total_time_ML += [total_time]\n",
    "            num_solves += [n_evals]\n",
    "\n",
    "            true_cost = cost_test[ii]\n",
    "            costs_ip += [true_cost]\n",
    "            total_time_ip += [times_test[ii]]\n",
    "\n",
    "            cost_ratios += [cost / true_cost]\n",
    "        count += 1\n",
    "    except (KeyboardInterrupt, SystemExit):\n",
    "        raise\n",
    "    except:\n",
    "        print('Solver failed at {}'.format(ii))\n",
    "        gurobi_fail += 1\n",
    "        continue\n",
    "\n",
    "costs = np.array(costs)\n",
    "cost_ratios = np.array(cost_ratios)\n",
    "total_time_ML = np.array(total_time_ML)\n",
    "num_solves = np.array(num_solves, dtype=int)\n",
    "\n",
    "costs_ip = np.array(costs_ip)\n",
    "total_time_ip = np.array(total_time_ip)\n",
    "\n",
    "percentage = 100 * float(n_succ) / float(count)\n",
    "dict = {'framework':framework,'N':N,'n_obs':n_obs,'costs':costs, 'total_time_ML':total_time_ML,'num_solves':num_solves, 'costs_ip':costs_ip, 'total_time_ip':total_time_ip, 'cost_ratios':cost_ratios,'strategies':MPC_obj.n_strategies,'percentage':percentage,}\n",
    "f_save = open(dataset_fn+'/result.pkl', 'wb')\n",
    "pickle.dump(dict, f_save)\n",
    "f_save.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'framework': 'OMISTL', 'costs': array([141.64417486,  26.88436094,  13.89747605, ...,  11.38300457,\n",
      "        36.19873741,  86.40482951]), 'total_time_ML': array([0.01562309, 0.        , 0.        , ..., 0.03125191, 0.        ,\n",
      "       0.01562691]), 'num_solves': array([1, 1, 1, ..., 5, 1, 1]), 'costs_ip': array([141.64424827,  26.88445664,  13.89748213, ...,  11.50938872,\n",
      "        36.19862202,  87.27345367]), 'total_time_ip': array([0.10700226, 0.22599792, 0.08699608, ..., 0.33400345, 0.20100021,\n",
      "       0.53097534]), 'cost_ratios': array([0.99999948, 0.99999644, 0.99999956, ..., 0.98901904, 1.00000319,\n",
      "       0.9900471 ]), 'percentage': 92.90853031860226}\n"
     ]
    }
   ],
   "source": [
    "# load results\n",
    "N = 8\n",
    "n_obs = 10\n",
    "results = load_result(N=N,n_obs=n_obs)\n",
    "print(results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## test results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(5,11):\n",
    "    test_strategy(10,i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## load results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nubmber of strategies:983\n",
      "n_obs: 10\n",
      "N: 8\n",
      "Loading presaved classifier model from D:\\Curious\\OMISTL\\models\\MPC_horizon_8_obs_10.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 40/400 [00:04<00:40,  8.96it/s]D:\\Curious\\OMISTL\\MPC\\test_results.py:151: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  cost_ratios += [cost / true_cost]\n",
      "100%|██████████| 400/400 [00:47<00:00,  8.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'framework': 'OMISTL', 'N': 8, 'n_obs': 10, 'costs': array([141.64442018,  26.88449467,  13.93885186,  46.78793655,\n",
      "        12.25665451,  11.23002882, 139.03191223,  18.07905173,\n",
      "         7.44513687,  32.38252204,  31.92416317, 119.50552848,\n",
      "        49.80212125,  38.75261684,  12.67942196,  74.40904183,\n",
      "       182.63635626,  16.29953153,  21.13723826,  75.43351822,\n",
      "         0.23010067, 135.74781941,  28.84837085,   0.53481933,\n",
      "       124.48478887,  60.94744965,   2.730527  ,   0.59833686,\n",
      "        25.0226615 ,   0.71523936,  25.18142728, 183.24370146,\n",
      "         5.71966028,  38.24558756,  45.44856601,  77.81518523,\n",
      "        33.12888089,  47.75725202,   1.8876952 ,  83.83234515,\n",
      "        21.92838841,  23.50202034,  16.32376313,   1.11274229,\n",
      "        30.02099011, 107.84987127,  71.57196249,  25.8845697 ,\n",
      "        10.61862588,  49.68459529,  30.86404869,  10.80044839,\n",
      "        14.00631559,  79.91761299,  57.62274463,   0.40072968,\n",
      "         7.27641024,   7.64083252,  14.49020848,  97.49568855,\n",
      "        16.49004421,   2.75435453,   9.82608227,  53.11648407,\n",
      "         4.01121642,   6.15712898,   8.69089877,  85.48953415,\n",
      "         2.35683222,  72.07076837,  28.02986824,  10.2704276 ,\n",
      "        18.86501247, 146.25478313,  20.06372808,   0.69358219,\n",
      "       101.31977928,  37.87762157,  42.64717439,   2.84736773,\n",
      "        16.7750382 ,  46.37566524, 112.6657863 ,  17.59406961,\n",
      "        78.86921595, 147.8306344 ,  24.00392303,  12.83969693,\n",
      "        44.6322287 ,  82.57242054,  38.92187898,   2.9907463 ,\n",
      "        71.56529628,  33.86952728,  18.41289622,  31.74798525,\n",
      "        21.10694607,  60.93364205,   6.30229229,   8.62331004,\n",
      "         3.84302975,  46.71772473,   0.41740401,  79.04400314,\n",
      "        99.24994537,  19.98724797,  76.5476268 , 135.78858156,\n",
      "         0.9901871 ,  14.66334106,  26.61367324,  77.68466388,\n",
      "         3.63583371,  32.03322731,   4.23648478,  80.59953421,\n",
      "        19.85266719,  15.39584616,   3.66015119,  26.99223977,\n",
      "        90.27595841,  14.78846533, 128.22471146,   2.86716175,\n",
      "        37.49828227, 173.91210795,  17.28465642,  84.48127531,\n",
      "        21.10504505,   6.14582617, 172.49636129,  15.61470692,\n",
      "        67.59289756,  16.05630536,  69.06155978,  69.35019112,\n",
      "        23.80081169,  74.74989634,  40.73283103,  52.1116829 ,\n",
      "        34.3555457 ,  31.78787165,   8.13830555, 162.49027318,\n",
      "         6.79369649,  65.84642462,   9.81312617,  23.0697767 ,\n",
      "        39.70826725,  63.14535644,  71.77364983, 148.78514797,\n",
      "         0.41610039,  47.22077622,  66.32865086,  76.82065407,\n",
      "        74.9894224 ,   4.29691223,  73.84036281,  33.12152895,\n",
      "        34.43504552,   2.59171604,  73.65727294,  20.93238522,\n",
      "        56.95864735, 100.41729903, 137.97307969,  76.46546227,\n",
      "         9.06505075,  40.20583298,  86.09749512,  18.0512304 ,\n",
      "        27.52387276,  61.22131761,  23.79220881, 157.15687771,\n",
      "        34.82633793,  63.94842049,  22.98963233,   3.05272041,\n",
      "        40.32167217,  46.08049491,  88.12059663,  89.22942717,\n",
      "        18.20751138,  45.29877531,  61.39223978,  26.89628625,\n",
      "         3.85599492,  80.97042739,  43.33449691,  96.95693189,\n",
      "         7.79685268,  17.94366951,  15.71439129,   2.13066055,\n",
      "         9.61103943,  14.69073303,   0.32177514, 131.1245431 ,\n",
      "        15.07257214,  35.71596973,  42.80658197,  21.17932383,\n",
      "        10.85976837, 143.41897996,  55.86610965,   2.25121314,\n",
      "       145.61430028,   1.18083466,  64.51352719,  41.93162363,\n",
      "        68.96438051,   3.82104811,  21.5725998 ,   0.52574153,\n",
      "        30.35880481,   4.83337168,  51.72819335, 117.15846107,\n",
      "        83.93865001,   1.40474123,   7.9503107 ,  58.36254884,\n",
      "        55.11234882,  13.21211305, 112.34370322,  60.0983683 ,\n",
      "       167.14588436,  49.88269906,  26.95564556,  58.48218455,\n",
      "        65.90255607,  21.83725719,  52.84086793,  29.56434414,\n",
      "        36.7096365 ,  20.97343071,  65.06992264,   2.36560879,\n",
      "        94.3207319 ,  30.73231023,   8.60560853,   0.32906055,\n",
      "         3.26455463,  77.34998286,   1.37435225, 148.26189909,\n",
      "        90.88235521,  57.78611104,  29.14731133,  84.48769877,\n",
      "        13.52164399, 115.22586605,   3.33026127,   1.62381082,\n",
      "        69.73679479,  48.67338183,  53.97453182,  35.95347335,\n",
      "        29.05180694, 110.77664383,  77.98690655,  13.89660731,\n",
      "        59.31400569,  85.93894785,   2.60676083,  81.49509933,\n",
      "        70.32864152,   9.38224033,   0.78537268,   1.56613665,\n",
      "       180.15701754,   0.79183227,  11.71612983,  32.55840384,\n",
      "       100.79614649,   5.19048678,  78.38352701, 108.32854409,\n",
      "       126.68738085,  94.40932066,  48.0031463 ,  81.32499002,\n",
      "        50.65945865,  14.64515186,   1.93091049,   7.6019057 ,\n",
      "        18.10824128,   2.83449477,  11.06544802,  32.26193014,\n",
      "        11.69409478,  83.26130196,  28.61491434,  10.04596967,\n",
      "        67.85942249,  96.95389444,  17.85978324,  63.04544644,\n",
      "        63.35938468,  53.63835364,  76.03599657,  29.57097648,\n",
      "        13.57300381,  44.28320637,   0.65143503,  28.86629761,\n",
      "       146.20553472, 122.98144258,   1.07574679,  30.6597437 ,\n",
      "        19.16153545,  47.45817972, 151.04893182,  57.99307209,\n",
      "       122.91279041,  41.8184136 ,   1.08987379,  10.23118864,\n",
      "        23.83965538,   1.09324805, 139.34081927,  67.76595904,\n",
      "         7.78851517,  55.47253653,  27.44288285,  38.53271642,\n",
      "        98.54222271,  70.83115351,  13.35797401,  72.25981067,\n",
      "        84.76345492,  26.64928975,  29.45901222,  33.48631104,\n",
      "         6.51829213,  39.0065809 ,  32.18025373,   0.23809259,\n",
      "         2.14878306, 153.60691512,  32.47160763,   6.24637542,\n",
      "       125.62439965,   5.18465041,  58.09408294,  28.08573932,\n",
      "        49.35282107,  40.55570046, 174.57394503,  14.80702848,\n",
      "         7.62584797,  48.34665458,   2.02058279,  97.60593627,\n",
      "        12.93610352,  23.59362423,  20.38384129,  26.3491946 ,\n",
      "         1.34813815,   0.70182032,  10.784872  ,  39.87523892,\n",
      "       168.68799478,  27.74610031, 114.40941046,  40.76444813,\n",
      "        99.13171839,  43.36906206, 122.48319165,  52.2477184 ,\n",
      "        34.60037072,  24.66413662,  30.80354453,  81.178966  ,\n",
      "         4.97591953,  42.49591107]), 'total_time_ML': array([0.063     , 0.        , 0.015625  , 0.078     , 0.047     ,\n",
      "       0.04662333, 0.016     , 0.016     , 0.        , 0.031     ,\n",
      "       0.063     , 0.015     , 0.047     , 0.016     , 0.173     ,\n",
      "       0.094     , 0.031     , 0.14      , 0.016     , 0.031     ,\n",
      "       0.016     , 0.047     , 0.016     , 0.015     , 0.04762381,\n",
      "       0.        , 0.07862738, 0.063     , 0.016     , 0.047     ,\n",
      "       0.016     , 0.202     , 0.047     , 0.06300088, 0.        ,\n",
      "       0.094     , 0.063     , 0.077     , 0.063     , 0.062     ,\n",
      "       0.016     , 0.11      , 0.047     , 0.046     , 0.094     ,\n",
      "       0.11      , 0.031     , 0.047     , 0.078     , 0.031     ,\n",
      "       0.016     , 0.03163001, 0.047     , 0.047     , 0.047     ,\n",
      "       0.031     , 0.078     , 0.016     , 0.06161713, 0.047     ,\n",
      "       0.016     , 0.016     , 0.047     , 0.        , 0.03059067,\n",
      "       0.031     , 0.047     , 0.031     , 0.032     , 0.015     ,\n",
      "       0.062     , 0.047     , 0.031     , 0.016     , 0.062     ,\n",
      "       0.031     , 0.031     , 0.5       , 0.094     , 0.031     ,\n",
      "       0.046     , 0.015     , 0.015     , 0.031     , 0.062     ,\n",
      "       0.047     , 0.031     , 0.016     , 0.10962643, 0.126     ,\n",
      "       0.046     , 0.062     , 0.063     , 0.047     , 0.438     ,\n",
      "       0.016     , 0.04662619, 0.047     , 0.        , 0.078     ,\n",
      "       0.016     , 0.03062738, 0.031     , 0.015     , 0.094     ,\n",
      "       0.11      , 0.094     , 0.047     , 0.063     , 0.031     ,\n",
      "       0.031     , 0.297     , 0.156     , 0.015     , 0.016     ,\n",
      "       0.047     , 0.015     , 0.063     , 0.016     , 0.032     ,\n",
      "       0.078     , 0.031     , 0.047     , 0.031     , 0.047     ,\n",
      "       0.016     , 0.031     , 0.031     , 0.016     , 0.047     ,\n",
      "       0.031     , 0.016     , 0.031     , 0.016     , 0.062     ,\n",
      "       0.015     , 0.016     , 0.016     , 0.079     , 0.        ,\n",
      "       0.        , 0.046     , 0.015     , 0.047     , 0.016     ,\n",
      "       0.016     , 0.031     , 0.016     , 0.094     , 0.015     ,\n",
      "       0.046     , 0.094     , 0.047     , 0.047     , 0.079     ,\n",
      "       0.032     , 0.016     , 0.0476281 , 0.062     , 0.047     ,\n",
      "       0.078     , 0.        , 0.203     , 0.        , 0.047     ,\n",
      "       0.125     , 0.        , 0.406     , 0.03158995, 0.047     ,\n",
      "       0.047     , 0.094     , 0.047     , 0.015     , 0.047     ,\n",
      "       0.047     , 0.093     , 0.015     , 0.172     , 0.093     ,\n",
      "       0.015     , 0.07862572, 0.03400057, 0.031     , 0.015     ,\n",
      "       0.093     , 0.015     , 0.016     , 0.031     , 0.032     ,\n",
      "       0.124     , 0.016     , 0.047     , 0.047     , 0.063     ,\n",
      "       0.015     , 0.015     , 0.031     , 0.047     , 0.408     ,\n",
      "       0.015     , 0.047     , 0.016     , 0.047     , 0.063     ,\n",
      "       0.015     , 0.015     , 0.031     , 0.031     , 0.016     ,\n",
      "       0.016     , 0.046     , 0.047     , 0.047     , 0.078     ,\n",
      "       0.046     , 0.062     , 0.016     , 0.094     , 0.015     ,\n",
      "       0.047     , 0.015     , 0.093     , 0.016     , 0.048     ,\n",
      "       0.063     , 0.047     , 0.156     , 0.06262643, 0.11      ,\n",
      "       0.016     , 0.062     , 0.04799993, 0.047     , 0.016     ,\n",
      "       0.016     , 0.093     , 0.015     , 0.063     , 0.016     ,\n",
      "       0.047     , 0.015     , 0.015     , 0.094     , 0.047     ,\n",
      "       0.094     , 0.        , 0.047     , 0.032     , 0.516     ,\n",
      "       0.016     , 0.093     , 0.015     , 0.016     , 0.047     ,\n",
      "       0.        , 0.        , 0.016     , 0.047     , 0.125     ,\n",
      "       0.063     , 0.016     , 0.046     , 0.25      , 0.094     ,\n",
      "       0.641     , 0.016     , 0.14      , 0.032     , 0.047     ,\n",
      "       0.015     , 0.06262619, 0.016     , 0.109     , 0.047     ,\n",
      "       0.06262524, 0.047     , 0.094     , 0.015     , 0.141     ,\n",
      "       0.047     , 0.063     , 0.015     , 0.047     , 0.        ,\n",
      "       0.047     , 0.047     , 0.047     , 0.047     , 0.109     ,\n",
      "       0.047     , 0.047     , 0.359     , 0.078     , 0.062     ,\n",
      "       0.03162715, 0.        , 0.047     , 0.031     , 0.032     ,\n",
      "       0.0306219 , 0.047     , 0.016     , 0.031     , 0.063     ,\n",
      "       0.015     , 0.062     , 0.016     , 0.        , 0.00099969,\n",
      "       0.00099945, 0.01699747, 0.00225019, 0.032     , 0.031     ,\n",
      "       0.016     , 0.015     , 0.078     , 0.        , 0.078     ,\n",
      "       0.031     , 0.031     , 0.03200088, 0.062     , 0.124     ,\n",
      "       0.        , 0.094     , 0.016     , 0.109     , 0.016     ,\n",
      "       0.031     , 0.016     , 0.125     , 0.06262595, 0.016     ,\n",
      "       0.173     , 0.046     , 0.062     , 0.172     , 0.07896822,\n",
      "       0.        , 0.015     , 0.156     , 0.015     , 0.094     ,\n",
      "       0.063     , 0.09465886, 0.047     , 0.015     , 0.047     ,\n",
      "       0.51662333, 0.031     , 0.031     , 0.03      , 0.06262738,\n",
      "       0.109     , 0.016     , 0.078     , 0.015     , 0.032     ,\n",
      "       0.031     , 0.125     , 0.031     , 0.218     , 0.047     ,\n",
      "       0.06262715, 0.078     , 0.047     , 0.031     , 0.063     ,\n",
      "       0.016     , 0.015     , 0.063     , 0.047     , 0.016     ,\n",
      "       0.031     , 0.047     , 0.015     ]), 'num_solves': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 2, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 3, 1, 1, 1, 1, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 6, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 8, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 3, 1, 1, 1,\n",
      "       1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1,\n",
      "       1, 1, 3, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 2, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5,\n",
      "       1, 9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2, 1, 1, 1, 3, 1,\n",
      "       1, 1, 1, 1, 1, 4, 1, 1, 5, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 8, 1,\n",
      "       1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1]), 'costs_ip': array([141.64424827,  26.88445664,  13.89748213,  46.78785922,\n",
      "        17.08923318,  11.22991768, 139.03191794,  18.07905035,\n",
      "         7.44510074,  32.38243288,  31.92409022, 117.63875201,\n",
      "        45.88979558,  38.75261619,  11.56722104,  73.26616225,\n",
      "       181.33991795,  16.29950932,  20.91533247,  77.63554204,\n",
      "         0.2301003 , 135.74743523,  27.57955057,   0.53746993,\n",
      "       124.48473243,  60.94742336,   2.73051553,   0.5983356 ,\n",
      "        25.03303479,   0.71523905,  25.18139672, 181.11076516,\n",
      "         5.71964363,  41.69322524,  45.44835624,  77.8150058 ,\n",
      "        33.1288734 ,   0.        ,   1.88769029,  83.8311761 ,\n",
      "        21.92835345,  23.20032809,  16.32371412,   1.11274199,\n",
      "        30.02097335, 107.84952934,  71.57196261,  25.88449669,\n",
      "        11.60166836,  49.68407517,  30.8639715 ,  10.80043599,\n",
      "        14.0062465 ,  79.91728475,  57.77849413,   0.4007302 ,\n",
      "         7.27639891,   7.64081512,  14.49864929,  97.49538422,\n",
      "        16.48935696,   2.81244207,   9.82605791,  53.11617972,\n",
      "         3.95278967,   6.15709965,   8.81186535,  96.64550737,\n",
      "         2.35683226,  72.07063589,   0.        ,  10.27041352,\n",
      "        18.86496972,   0.        ,  20.06370165,   0.69358251,\n",
      "        98.84603264,   0.        ,  44.02866909,   2.84736154,\n",
      "        16.77500321,  46.3756251 , 111.59706032,  18.7344769 ,\n",
      "        78.81327426, 147.22787765,  23.95506251,  12.83958941,\n",
      "        44.72175824,  82.57235873,  38.92180005,   2.99074616,\n",
      "        71.56529073,  30.07466353,  18.41288831,   0.        ,\n",
      "        21.10691613,  61.25127302,   6.30227195,   8.62330975,\n",
      "         3.84301935,  47.1538709 ,   0.        ,  79.62485956,\n",
      "        99.2496668 ,  19.98717589,  75.38948951, 135.59729202,\n",
      "         0.99018674,  14.66332334,  26.56581744,  77.82182322,\n",
      "         3.63583017,  32.03313456,   4.23651728,  80.59948255,\n",
      "        19.85263228,  15.39583113,   3.6601516 ,  26.47740541,\n",
      "        92.40942405,  17.36495869, 128.22470952,   0.        ,\n",
      "        37.49814268, 173.91208516,  17.28465531,  84.48123089,\n",
      "        19.74085139,   0.        , 171.63818663,  21.80853883,\n",
      "        64.4566137 ,  16.57901165,  69.0614751 ,  69.35011956,\n",
      "        23.76207157,  79.12749829,  40.74828123,  46.64295735,\n",
      "        34.3555402 ,  31.31713307,   8.13830696, 162.48968984,\n",
      "         6.79367367,  64.70942009,   9.81313091,  22.87358982,\n",
      "        39.4983399 ,  63.14531999,  72.60336353, 148.78505038,\n",
      "         0.41610054,  47.22076629,  66.32866902,  76.82047005,\n",
      "        74.99792827,   4.29690939,  73.84032334,  33.12147446,\n",
      "        34.43243156,   2.59167893,  73.60238595,  20.93215585,\n",
      "        56.95862671,  99.05495705, 137.97279871,  78.36738108,\n",
      "         9.06484344,  40.10175183,   0.        ,  26.48963605,\n",
      "        27.52370201,  61.10607419,  23.79211541, 157.15642724,\n",
      "        34.87083435,  61.00057831,  22.98950006,   3.05270482,\n",
      "        40.32164149,  46.08044764,  88.12043005,  89.2294025 ,\n",
      "        18.2074887 ,  45.2985522 ,  61.39436573,  26.89627969,\n",
      "         3.85598099,  80.72675333,  43.22004497,  87.7697446 ,\n",
      "         7.6961364 ,  17.94367051,   0.        ,   2.13065824,\n",
      "         9.61099761,  14.69064134,   0.32177528, 129.96689981,\n",
      "        15.07943607,  35.71590517,  40.39881875,  22.15169682,\n",
      "        10.85963207, 143.41897653,  55.8661103 ,   2.25120904,\n",
      "       145.61465185,   1.18082413,  65.45512614,  41.93162182,\n",
      "        68.96439355,   3.82102045,  21.57237472,   0.52574121,\n",
      "        30.35864079,   4.8333706 ,  49.61171519, 117.15840157,\n",
      "        83.93860141,   1.40474187,  10.33065264,  58.36252916,\n",
      "        54.81920308,  14.62585089, 111.23627221,   0.        ,\n",
      "       167.14553013,  49.87630435,  28.16162956,  58.48211091,\n",
      "        65.90246016,  21.83712605,  52.84046248,  29.56429233,\n",
      "        36.70886443,  20.97336002,  62.55682555,   2.36559149,\n",
      "         0.        ,  30.76180217,   8.4336856 ,   0.32906112,\n",
      "         3.26452287,  77.3498196 ,   1.03714946, 148.26189609,\n",
      "        89.040066  ,  57.78609634,  34.6664778 ,  84.48761936,\n",
      "        13.52163319, 115.22574159,   3.33025341,   1.62381121,\n",
      "        69.73665023,  48.67332357,  53.97333133,  35.95346521,\n",
      "        29.05179909,   0.        ,  77.98682599,  14.34002715,\n",
      "        59.31396412,  85.87797173,   2.60673766,  81.49494515,\n",
      "        70.32852512,   9.38220554,   0.78536522,   1.56611767,\n",
      "       180.15702526,   0.79183261,  11.39396859,  32.55815368,\n",
      "       100.79608065,   0.        ,  76.04107342, 108.32792268,\n",
      "       126.31333134,  94.40927108,  48.00310997,  81.18998582,\n",
      "         0.        ,  15.27049364,   2.0110934 ,   7.60187551,\n",
      "        18.10823316,   2.83448916,  11.06523636,  32.2618141 ,\n",
      "        11.69405451,  83.74645112,  28.6148316 ,   9.9646059 ,\n",
      "        67.85917283,  96.95384   ,  17.31832543,  63.04540121,\n",
      "        61.85706139,   0.        ,   0.        ,  29.57097621,\n",
      "        13.57292093,  44.28316354,   0.65143398,  29.12376056,\n",
      "       146.20523513, 123.15692972,   1.19843362,  30.65967562,\n",
      "        18.40496191,  47.84507972, 151.04881574,  57.99307239,\n",
      "       122.91260525,  41.81829471,   1.08987283,  10.23986033,\n",
      "        23.83965586,   1.09324869, 138.10918925,  67.19133226,\n",
      "         7.78848517,  55.44487402,  24.93156492,  38.53269224,\n",
      "        98.54209747,  68.31728365,  13.35797594,  85.41342658,\n",
      "        84.7634543 ,  26.64921732,  29.31593514,  33.48617645,\n",
      "         6.51819789,  40.66255067,  31.83871469,   0.23438172,\n",
      "         2.08670398, 153.6069068 ,  36.85566335,   6.24634996,\n",
      "       125.62389819,   4.61243193,  58.09408371,   0.        ,\n",
      "        49.35281982,  40.55566392, 174.57393015,  14.80700616,\n",
      "         0.        ,  48.34665065,   2.02058369,  97.60579419,\n",
      "        12.98494848,  23.59362829,  20.38372104,  26.34911375,\n",
      "         1.31291904,   0.70181528,  11.22811833,  39.07514541,\n",
      "       168.68762153,  27.74596787, 114.40913109,  40.76430649,\n",
      "        96.44742678,  43.36894401, 122.48299612,  52.24769487,\n",
      "        34.60033946,  24.66408146,  30.80302643,  81.17891931,\n",
      "         4.97591271,  42.49585893]), 'total_time_ip': array([0.10700226, 0.22599792, 0.08699608, 0.12927818, 0.12496758,\n",
      "       0.15803528, 0.02899551, 0.08999825, 0.12501144, 0.11098099,\n",
      "       0.21299934, 0.07096291, 0.12300491, 0.20500183, 0.07999992,\n",
      "       0.12401009, 0.78100204, 0.11599922, 0.2538662 , 0.0949955 ,\n",
      "       0.14200783, 0.22800636, 0.07999992, 0.15501785, 0.13195229,\n",
      "       0.17897987, 0.16200447, 0.09710503, 0.17597961, 0.09803581,\n",
      "       0.15957642, 0.19400215, 0.11010361, 0.3305397 , 0.22800255,\n",
      "       0.55483437, 0.11999702, 0.        , 0.1517849 , 0.20100021,\n",
      "       0.17307091, 0.10699463, 0.18000412, 0.28771973, 0.03996468,\n",
      "       0.1899662 , 0.09200668, 0.1819973 , 0.21500206, 0.21600342,\n",
      "       0.17003822, 0.31300926, 0.06899834, 0.36300468, 0.23600006,\n",
      "       0.11488342, 0.13496971, 0.09720421, 0.35403252, 0.13183784,\n",
      "       0.08600426, 0.27498436, 0.22900009, 0.14296532, 0.25800133,\n",
      "       0.06199646, 0.19400215, 0.10599899, 0.04858971, 0.36899757,\n",
      "       0.        , 0.12399483, 0.20802879, 0.        , 0.1949749 ,\n",
      "       0.17499542, 0.17103577, 0.        , 0.1519928 , 0.07636452,\n",
      "       0.236166  , 0.04100227, 0.03998375, 0.34955597, 0.04950714,\n",
      "       0.09398651, 0.20399857, 0.16799927, 0.2009716 , 0.09698296,\n",
      "       0.34996796, 0.11299706, 0.26600266, 0.40284538, 0.20199966,\n",
      "       0.        , 0.04861069, 0.05100822, 0.10499382, 0.15273666,\n",
      "       0.32800674, 0.13997459, 0.        , 0.20398712, 0.21600723,\n",
      "       0.11616707, 0.25861549, 0.27226639, 0.14499092, 0.07297897,\n",
      "       0.20700073, 0.27200127, 0.28901291, 0.07104492, 0.10196686,\n",
      "       0.27086067, 0.06202888, 0.29839897, 0.09599304, 0.16601562,\n",
      "       0.14568138, 0.17396736, 0.06299782, 0.        , 0.21391487,\n",
      "       0.02600098, 0.04857826, 0.23500252, 0.28297615, 0.        ,\n",
      "       0.16053772, 0.09000206, 0.16200829, 0.29199219, 0.11699677,\n",
      "       0.12601662, 0.14399529, 0.15903664, 0.10899353, 0.30335426,\n",
      "       0.15600586, 0.20181274, 0.16001129, 0.18099594, 0.10300064,\n",
      "       0.13999939, 0.24800491, 0.26199532, 0.27999878, 0.1741848 ,\n",
      "       0.36303329, 0.19400024, 0.22299385, 0.10997009, 0.10500908,\n",
      "       0.08799553, 0.19499779, 0.08100891, 0.38279343, 0.11243057,\n",
      "       0.07602882, 0.09243202, 0.09196091, 0.08485794, 0.31102562,\n",
      "       0.24394417, 0.11801529, 0.31756973, 0.17099762, 0.1710186 ,\n",
      "       0.        , 0.1870327 , 0.21102524, 0.3957901 , 0.25100136,\n",
      "       0.06502533, 0.37501907, 0.13797951, 0.17050171, 0.18399811,\n",
      "       0.17695427, 0.19399643, 0.08354759, 0.02400208, 0.19096565,\n",
      "       0.16399956, 0.11301231, 0.06674194, 0.12600517, 0.13047981,\n",
      "       0.06241226, 0.09300804, 0.13498116, 0.1180191 , 0.        ,\n",
      "       0.33000374, 0.16098213, 0.22650337, 0.10463524, 0.14574432,\n",
      "       0.19900131, 0.07200241, 0.27301025, 0.32500458, 0.30698776,\n",
      "       0.02600479, 0.06210518, 0.13600731, 0.15502548, 0.18499565,\n",
      "       0.08097458, 0.1469841 , 0.0710144 , 0.26102257, 0.16196632,\n",
      "       0.14800453, 0.17297935, 0.0852108 , 0.52903366, 0.50696754,\n",
      "       0.08342171, 0.2029953 , 0.12600327, 0.11500168, 0.19072151,\n",
      "       0.34601021, 0.08997345, 0.        , 0.16505241, 0.88499451,\n",
      "       0.40195465, 0.07295227, 0.19603539, 0.13399315, 0.27832413,\n",
      "       0.43099976, 0.10389328, 0.25901604, 0.17797279, 0.24301147,\n",
      "       0.        , 0.17497826, 0.22099876, 0.11600113, 0.19998741,\n",
      "       0.40092659, 0.13200569, 0.03399658, 0.40400314, 0.32899094,\n",
      "       0.22209549, 0.36499214, 0.27725601, 0.17900276, 0.109375  ,\n",
      "       0.20967484, 0.20896912, 0.16602707, 0.18201065, 0.17200279,\n",
      "       0.03198814, 0.        , 0.29000664, 0.15399933, 0.10699844,\n",
      "       0.24187469, 0.07699966, 0.29899979, 0.54700089, 0.13102722,\n",
      "       0.17500877, 0.20057869, 0.07200241, 0.16399574, 0.11699486,\n",
      "       0.08948708, 0.14396095, 0.        , 0.26200867, 0.26799202,\n",
      "       0.11600304, 0.08499718, 0.10896683, 0.23800087, 0.        ,\n",
      "       0.10196495, 0.09300232, 0.27900696, 0.08699417, 0.13600349,\n",
      "       0.24554443, 0.15167809, 0.18267822, 0.26200104, 0.19963264,\n",
      "       0.33032036, 0.17419052, 0.07008553, 0.19800377, 0.25672913,\n",
      "       0.27899933, 0.        , 0.        , 0.13500595, 0.10297775,\n",
      "       0.29199409, 0.09500694, 0.2820282 , 0.17702484, 0.1210289 ,\n",
      "       0.0929966 , 0.32596779, 0.14697647, 0.23498917, 0.20100021,\n",
      "       0.08899689, 0.10397148, 0.33799553, 0.12599182, 0.36300278,\n",
      "       0.48362732, 0.09599876, 0.22500038, 0.32500076, 0.09019089,\n",
      "       0.26002884, 0.24200439, 0.1769886 , 0.09853363, 0.17298889,\n",
      "       0.09600639, 0.12803078, 0.02398682, 0.12271881, 0.20301056,\n",
      "       0.2029953 , 0.13024521, 0.43607712, 0.14902115, 0.37801361,\n",
      "       0.13599777, 0.03904152, 0.25701332, 0.09397697, 0.30399895,\n",
      "       0.1000042 , 0.09244156, 0.        , 0.02601433, 0.256464  ,\n",
      "       0.06599617, 0.11700058, 0.        , 0.12281227, 0.10500145,\n",
      "       0.05799866, 0.32321548, 0.12417412, 0.1670208 , 0.37496948,\n",
      "       0.168993  , 0.10697746, 0.22700119, 0.09902763, 0.31599808,\n",
      "       0.09376907, 0.3279953 , 0.12196732, 0.23001862, 0.19003677,\n",
      "       0.20800209, 0.03703499, 0.13697815, 0.23199272, 0.10419083,\n",
      "       0.13899994, 0.24102974, 0.11234856]), 'cost_ratios': array([1.00000121, 1.00000141, 1.00297678, 1.00000165, 0.71721501,\n",
      "       1.0000099 , 0.99999996, 1.00000008, 1.00000485, 1.00000275,\n",
      "       1.00000229, 1.01586872, 1.08525481, 1.00000002, 1.09615109,\n",
      "       1.01559901, 1.00714922, 1.00000136, 1.01060972, 0.9716364 ,\n",
      "       1.00000163, 1.00000283, 1.04600584, 0.99506839, 1.00000045,\n",
      "       1.00000043, 1.0000042 , 1.0000021 , 0.99958562, 1.00000042,\n",
      "       1.00000121, 1.01177697, 1.00000291, 0.9173094 , 1.00000462,\n",
      "       1.00000231, 1.00000023,        inf, 1.0000026 , 1.00001395,\n",
      "       1.00000159, 1.01300379, 1.000003  , 1.00000027, 1.00000056,\n",
      "       1.00000317, 1.        , 1.00000282, 0.91526714, 1.00001047,\n",
      "       1.0000025 , 1.00000115, 1.00000493, 1.00000411, 0.99730437,\n",
      "       0.99999869, 1.00000156, 1.00000228, 0.99941782, 1.00000312,\n",
      "       1.00004168, 0.97934623, 1.00000248, 1.00000573, 1.01478114,\n",
      "       1.00000476, 0.98627231, 0.88456811, 0.99999998, 1.00000184,\n",
      "              inf, 1.00000137, 1.00000227,        inf, 1.00000132,\n",
      "       0.99999954, 1.02502626,        inf, 0.96862284, 1.00000218,\n",
      "       1.00000209, 1.00000087, 1.00957665, 0.93912788, 1.0007098 ,\n",
      "       1.00409404, 1.00203967, 1.00000837, 0.99799808, 1.00000075,\n",
      "       1.00000203, 1.00000005, 1.00000008, 1.12618142, 1.00000043,\n",
      "              inf, 1.00000142, 0.9948143 , 1.00000323, 1.00000003,\n",
      "       1.00000271, 0.99075058,        inf, 0.99270509, 1.00000281,\n",
      "       1.00000361, 1.01536205, 1.00141072, 1.00000037, 1.00000121,\n",
      "       1.00180141, 0.99823752, 1.00000097, 1.0000029 , 0.99999233,\n",
      "       1.00000064, 1.00000176, 1.00000098, 0.99999989, 1.01944429,\n",
      "       0.9769129 , 0.85162686, 1.00000002,        inf, 1.00000372,\n",
      "       1.00000013, 1.00000006, 1.00000053, 1.06910511,        inf,\n",
      "       1.00499991, 0.71599051, 1.04865729, 0.96847181, 1.00000123,\n",
      "       1.00000103, 1.00163033, 0.9446766 , 0.99962084, 1.11724654,\n",
      "       1.00000016, 1.01503134, 0.99999983, 1.00000359, 1.00000336,\n",
      "       1.01757093, 0.99999952, 1.008577  , 1.00531484, 1.00000058,\n",
      "       0.98857197, 1.00000066, 0.99999964, 1.00000021, 0.99999973,\n",
      "       1.0000024 , 0.99988659, 1.00000066, 1.00000053, 1.00000165,\n",
      "       1.00007592, 1.00001432, 1.00074572, 1.00001096, 1.00000036,\n",
      "       1.0137534 , 1.00000204, 0.97573073, 1.00002287, 1.00259543,\n",
      "              inf, 0.68144501, 1.0000062 , 1.00188596, 1.00000393,\n",
      "       1.00000287, 0.99872396, 1.04832482, 1.00000575, 1.00000511,\n",
      "       1.00000076, 1.00000103, 1.00000189, 1.00000028, 1.00000125,\n",
      "       1.00000493, 0.99996537, 1.00000024, 1.00000361, 1.0030185 ,\n",
      "       1.00264812, 1.10467374, 1.0130866 , 0.99999994,        inf,\n",
      "       1.00000108, 1.00000435, 1.00000624, 0.99999958, 1.00890722,\n",
      "       0.99954482, 1.00000181, 1.05959984, 0.95610391, 1.00001255,\n",
      "       1.00000002, 0.99999999, 1.00000182, 0.99999759, 1.00000892,\n",
      "       0.98561459, 1.00000004, 0.99999981, 1.00000724, 1.00001043,\n",
      "       1.00000061, 1.0000054 , 1.00000022, 1.04266085, 1.00000051,\n",
      "       1.00000058, 0.99999954, 0.76958455, 1.00000034, 1.0053475 ,\n",
      "       0.90333979, 1.00995566,        inf, 1.00000212, 1.00012821,\n",
      "       0.95717634, 1.00000126, 1.00000146, 1.00000601, 1.00000767,\n",
      "       1.00000175, 1.00002103, 1.00000337, 1.04017303, 1.00000731,\n",
      "              inf, 0.99904128, 1.02038527, 0.99999826, 1.00000973,\n",
      "       1.00000211, 1.32512458, 1.00000002, 1.02069056, 1.00000025,\n",
      "       0.84079241, 1.00000094, 1.0000008 , 1.00000108, 1.00000236,\n",
      "       0.99999976, 1.00000207, 1.0000012 , 1.00002224, 1.00000023,\n",
      "       1.00000027,        inf, 1.00000103, 0.96907817, 1.0000007 ,\n",
      "       1.00071003, 1.00000889, 1.00000189, 1.00000166, 1.00000371,\n",
      "       1.0000095 , 1.00001212, 0.99999996, 0.99999957, 1.02827472,\n",
      "       1.00000768, 1.00000065,        inf, 1.03080511, 1.00000574,\n",
      "       1.00296128, 1.00000053, 1.00000076, 1.00166282,        inf,\n",
      "       0.95904901, 0.96012969, 1.00000397, 1.00000045, 1.00000198,\n",
      "       1.00001913, 1.0000036 , 1.00000344, 0.99420693, 1.00000289,\n",
      "       1.00816528, 1.00000368, 1.00000056, 1.03126502, 1.00000072,\n",
      "       1.02428701,        inf,        inf, 1.00000001, 1.00000611,\n",
      "       1.00000097, 1.00000162, 0.99115969, 1.00000205, 0.99857509,\n",
      "       0.89762734, 1.00000222, 1.04110704, 0.99191348, 1.00000077,\n",
      "       0.99999999, 1.00000151, 1.00000284, 1.00000088, 0.99915314,\n",
      "       0.99999998, 0.99999941, 1.0089178 , 1.0085521 , 1.00000385,\n",
      "       1.00049892, 1.10072845, 1.00000063, 1.00000127, 1.03679698,\n",
      "       0.99999986, 0.84600061, 1.00000001, 1.00000272, 1.00488052,\n",
      "       1.00000402, 1.00001446, 0.95927531, 1.01072716, 1.0158326 ,\n",
      "       1.02974983, 1.00000005, 0.88104798, 1.00000408, 1.00000399,\n",
      "       1.12406004, 0.99999999,        inf, 1.00000003, 1.0000009 ,\n",
      "       1.00000009, 1.00000151,        inf, 1.00000008, 0.99999955,\n",
      "       1.00000146, 0.99623834, 0.99999983, 1.0000059 , 1.00000307,\n",
      "       1.02682505, 1.00000719, 0.96052354, 1.02047577, 1.00000221,\n",
      "       1.00000477, 1.00000244, 1.00000347, 1.02783166, 1.00000272,\n",
      "       1.0000016 , 1.00000045, 1.0000009 , 1.00000224, 1.00001682,\n",
      "       1.00000058, 1.00000137, 1.00000123]), 'strategies': 983, 'percentage': 96.67519181585678}\n"
     ]
    }
   ],
   "source": [
    "N = 8\n",
    "n_obs = 10\n",
    "test_strategy(N,n_obs)\n",
    "results = load_result(N=N,n_obs=n_obs)\n",
    "print(results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 10 obs: 5 success percentege: 90.76923076923077 number of strategies: 2202\n",
      "N: 10 obs: 6 success percentege: 86.85567010309278 number of strategies: 2173\n",
      "N: 10 obs: 7 success percentege: 87.30569948186529 number of strategies: 2437\n",
      "N: 10 obs: 8 success percentege: 82.68733850129199 number of strategies: 2615\n",
      "N: 10 obs: 9 success percentege: 81.25 number of strategies: 2617\n",
      "N: 10 obs: 10 success percentege: 90.55118110236221 number of strategies: 2871\n",
      "N: 12 obs: 5 success percentege: 87.59689922480621 number of strategies: 4580\n",
      "N: 12 obs: 6 success percentege: 85.8288770053476 number of strategies: 4336\n",
      "N: 12 obs: 7 success percentege: 82.47422680412372 number of strategies: 4287\n",
      "N: 12 obs: 8 success percentege: 72.63157894736842 number of strategies: 4958\n",
      "N: 12 obs: 9 success percentege: 77.4869109947644 number of strategies: 5991\n",
      "N: 12 obs: 10 success percentege: 76.5625 number of strategies: 6201\n",
      "[[90.76923076923077, 86.85567010309278, 87.30569948186529, 82.68733850129199, 81.25, 90.55118110236221], [87.59689922480621, 85.8288770053476, 82.47422680412372, 72.63157894736842, 77.4869109947644, 76.5625]]\n"
     ]
    }
   ],
   "source": [
    "from test_results import load_result\n",
    "N=12\n",
    "plot_horizons = [10,12]\n",
    "percent_successes = []\n",
    "for ii, N in enumerate(plot_horizons):\n",
    "    percent_successes_eachN = []\n",
    "    for idx_obs in range(5,11):\n",
    "        n_obs=idx_obs\n",
    "        results = load_result(N=N,n_obs=n_obs)\n",
    "        print('N: '+ str(N) + ' obs: '+ str(n_obs)+' success percentege: '+ str(results['percentage']) + ' number of strategies: '+ str(results['strategies']))\n",
    "        percent_successes_eachN.append(results['percentage'])\n",
    "    percent_successes.append(percent_successes_eachN)\n",
    "print(percent_successes)\n",
    "percent_successes[0][-1]=84.421"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 842.4x595.44 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(font_scale=2, font=\"serif\", style=\"whitegrid\")\n",
    "\n",
    "flierprops = {'alpha':0.5}\n",
    "# sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "\n",
    "linestyles = ['--', '-.', '-', ':']\n",
    "\n",
    "for ii, N in enumerate(plot_horizons):\n",
    "    batch_percent_success = percent_successes[ii]\n",
    "    xlabels = [ii for ii in range(0,6)]\n",
    "    x_labels = [ii for ii in range(5,11)]\n",
    "    y_labels = [batch_percent_success[x] for x in xlabels]\n",
    "    ax1 = sns.lineplot(x=x_labels, y=y_labels, palette=\"Set3\", label='N={}'.format(N), linewidth=1.5)\n",
    "    ax1.lines[ii].set_linestyle(linestyles[ii])\n",
    "    # ax1.set(xlabel=\"\", ylabel=\"Percent Success\")\n",
    "\n",
    "ax1.set(xlabel=\"Num. Obstacles\", ylabel=\"Percent Success [%]\")\n",
    "# ax1.grid(False)\n",
    "#\n",
    "yticks =  [10*ii for ii in range(11)]\n",
    "ax1.set_yticks(yticks)\n",
    "\n",
    "#\n",
    "plt.tight_layout()\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlim([5,10])\n",
    "# plt.xticks(fontsize=13)\n",
    "plt.ylim([60.,100.])\n",
    "# plt.yticks(fontsize=13)\n",
    "\n",
    "\n",
    "# sns.set_style(\"whitegrid\")\n",
    "st = sns.axes_style(\"whitegrid\")\n",
    "# sns.set_color_codes(\"\")\n",
    "\n",
    "figure = ax1.get_figure()\n",
    "my_path ='G:\\destop\\project\\SYCAMORE_report_template/figure'\n",
    "figure.savefig(my_path+\"/percent_success_mpc.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}